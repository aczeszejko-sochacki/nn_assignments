{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Embedding, LSTM, Dense, Dropout,\n",
    "                          Flatten, GRU, Conv1D, MaxPooling1D)\n",
    "\n",
    "# Other\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        self.word2ind = imdb.get_word_index()\n",
    "        self.ind2word = {ind: word for word, ind in self.word2ind.items()}\n",
    "        \n",
    "    def map_inds_to_words(self, inds: List) -> List:\n",
    "        return [self.ind2word.get(ind, '') for ind in inds]\n",
    "    \n",
    "    def map_words_to_inds(self, tokens: List) -> List:\n",
    "        return [self.word2ind.get(token, '') for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'as',\n",
       " 'you',\n",
       " 'with',\n",
       " 'out',\n",
       " 'themselves',\n",
       " 'powerful',\n",
       " 'lets',\n",
       " 'loves',\n",
       " 'their']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example part of a review\n",
    "preprocessing.map_inds_to_words(train_data[0])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the stopwords and delete them from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pozdrowiony/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "_stopwords = stopwords.words('english')\n",
    "\n",
    "# Check some english stopwords\n",
    "_stopwords[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map inds to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_data = [preprocessing.map_inds_to_words(rev) for rev in train_data]\n",
    "_test_data = [preprocessing.map_inds_to_words(rev) for rev in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_data = [[token for token in rev if token not in _stopwords] for rev in _train_data]\n",
    "_test_data = [[token for token in rev if token not in _stopwords] for rev in _test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map words to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_data = [preprocessing.map_words_to_inds(rev) for rev in _train_data]\n",
    "_test_data = [preprocessing.map_words_to_inds(rev) for rev in _test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = len(max((_train_data + _test_data), key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_data = sequence.pad_sequences(_train_data, maxlen=MAX_LEN)\n",
    "_test_data = sequence.pad_sequences(_test_data, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test various NN architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neccessery elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE=32\n",
    "\n",
    "# Define model paths\n",
    "DENSE_PATH = './data/dense_net.h5'\n",
    "DENSE_EMB_NOT_TRAIN_PATH = './data/dense_net_emb_not_train.h5'\n",
    "DENSE_1_HIDDEN_PATH = './data/dense_net_1_hidden.h5'\n",
    "\n",
    "LSTM_PATH = './data/lstm_net.h5'\n",
    "GRU_PATH = './data/gru_net.h5'\n",
    "\n",
    "CONV_1_LAYER_PATH = './data/conv_net_1_layer.h5'\n",
    "CONV_1_LAYER_EMB_NOT_TRAIN_PATH = './data/conv_net_emb_not_train.h5'\n",
    "CONV_1_LAYER_1_HIDDEN_PATH = './data/conv_net_1_1_hidden.h5'\n",
    "CONV_2_LAYERS_PATH = './data/conv_net_2.h5'\n",
    "CONV_2_LAYERS_1_HIDDEN_PATH = './data/conv_net_2_1_hidden.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_net(model: Sequential, file_path: str,\n",
    "                         override: bool = False) -> None:\n",
    "    \"\"\" Create or import the net if created \"\"\"\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Try to load the pretrained model\n",
    "    if not os.path.isfile(file_path) or override:     \n",
    "        model.fit(_train_data, train_labels,\n",
    "                  validation_split=0.2,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=N_EPOCHS)\n",
    "        \n",
    "        model.save(file_path)\n",
    "    else:\n",
    "        model = load_model(file_path)\n",
    "        \n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define embedding layer constant for each architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, input_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define list of the names of below nns and coresponding accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "nns = [\n",
    "    ['dense', 0, 'YES', 0],\n",
    "    ['dense', 0, 'NO', 0],\n",
    "    ['dense', 1, 'YES', 0],\n",
    "    ['lstm', 0, 'YES', 0],\n",
    "    ['gru', 0, 'YES', 0],\n",
    "    ['conv_1', 0, 'YES', 1],\n",
    "    ['conv_1', 0, 'NO', 1],\n",
    "    ['conv_1', 1, 'YES', 1],\n",
    "    ['conv_2', 0, 'YES', 2],\n",
    "    ['conv_2', 1, 'YES', 2],\n",
    "]\n",
    "columns = ['kind', 'n_hidden', 'emb_backprop', 'n_conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only input and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net = Sequential()\n",
    "dense_net.add(EMBEDDING)\n",
    "dense_net.add(Flatten())\n",
    "dense_net.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 15s 747us/step - loss: 0.5103 - acc: 0.7607 - val_loss: 0.3052 - val_acc: 0.8718\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 6s 297us/step - loss: 0.2260 - acc: 0.9157 - val_loss: 0.2771 - val_acc: 0.8850\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 11s 551us/step - loss: 0.1421 - acc: 0.9535 - val_loss: 0.2839 - val_acc: 0.8866\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 8s 383us/step - loss: 0.0857 - acc: 0.9779 - val_loss: 0.3023 - val_acc: 0.8848\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 7s 351us/step - loss: 0.0483 - acc: 0.9926 - val_loss: 0.3262 - val_acc: 0.8798\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 8s 407us/step - loss: 0.0270 - acc: 0.9976 - val_loss: 0.3490 - val_acc: 0.8774\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 7s 348us/step - loss: 0.0156 - acc: 0.9994 - val_loss: 0.3718 - val_acc: 0.8748\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 11s 557us/step - loss: 0.0097 - acc: 0.9999 - val_loss: 0.3933 - val_acc: 0.8760\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 6s 285us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4126 - val_acc: 0.8758\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 6s 277us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.4283 - val_acc: 0.8728\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 41600)             0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 41601     \n",
      "=================================================================\n",
      "Total params: 361,601\n",
      "Trainable params: 361,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(dense_net, DENSE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 124us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8616"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = dense_net.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only input and output layer without backpropagation on the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_emb_not_train = Sequential()\n",
    "dense_net_emb_not_train.add(EMBEDDING)\n",
    "dense_net_emb_not_train.add(Flatten())\n",
    "dense_net_emb_not_train.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Turn off the backprop on the embeddings\n",
    "dense_net_emb_not_train.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 12s 624us/step - loss: 0.2139 - acc: 0.9818 - val_loss: 0.2915 - val_acc: 0.8802\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.0647 - acc: 0.9987 - val_loss: 0.3070 - val_acc: 0.8774\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.0353 - acc: 0.9997 - val_loss: 0.3251 - val_acc: 0.8772\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 145us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.3427 - val_acc: 0.8760\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.3593 - val_acc: 0.8742\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3735 - val_acc: 0.8764\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 144us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3882 - val_acc: 0.8742\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 144us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4016 - val_acc: 0.8742\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 144us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4138 - val_acc: 0.8750\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 149us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4254 - val_acc: 0.8752\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 41600)             0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 41601     \n",
      "=================================================================\n",
      "Total params: 361,601\n",
      "Trainable params: 41,601\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(dense_net_emb_not_train, DENSE_EMB_NOT_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 132us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86128"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = dense_net_emb_not_train.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hidden layer and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DENSE_HIDDEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_1_hidden = Sequential()\n",
    "dense_net_1_hidden.add(EMBEDDING)\n",
    "dense_net_1_hidden.add(Flatten())\n",
    "dense_net_1_hidden.add(Dense(OUTPUT_DENSE_HIDDEN, activation='sigmoid'))\n",
    "dense_net_1_hidden.add(Dropout(0.1))\n",
    "dense_net_1_hidden.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0833 - acc: 0.9874 - val_loss: 0.3775 - val_acc: 0.8752\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4513 - val_acc: 0.8730\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4991 - val_acc: 0.8736\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5364 - val_acc: 0.8732\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 25s 1ms/step - loss: 6.3311e-04 - acc: 1.0000 - val_loss: 0.5648 - val_acc: 0.8734\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 4.3157e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.8700\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 3.1015e-04 - acc: 1.0000 - val_loss: 0.6131 - val_acc: 0.8744\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 2.2827e-04 - acc: 1.0000 - val_loss: 0.6378 - val_acc: 0.8722\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 25s 1ms/step - loss: 1.7511e-04 - acc: 1.0000 - val_loss: 0.6552 - val_acc: 0.8722\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 1.5267e-04 - acc: 1.0000 - val_loss: 0.6750 - val_acc: 0.8720\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 41600)             0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 100)               4160100   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 4,480,201\n",
      "Trainable params: 4,160,201\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(dense_net_1_hidden, DENSE_1_HIDDEN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 12s 465us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86116"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = dense_net_1_hidden.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_net = Sequential()\n",
    "lstm_net.add(EMBEDDING)\n",
    "lstm_net.add(LSTM(100))\n",
    "lstm_net.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 420s 21ms/step - loss: 0.2313 - acc: 0.9184 - val_loss: 0.3530 - val_acc: 0.8650\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 414s 21ms/step - loss: 0.1132 - acc: 0.9605 - val_loss: 0.3749 - val_acc: 0.8756\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 414s 21ms/step - loss: 0.2560 - acc: 0.8886 - val_loss: 0.3728 - val_acc: 0.8730\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 413s 21ms/step - loss: 0.0764 - acc: 0.9734 - val_loss: 0.3977 - val_acc: 0.8804\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 417s 21ms/step - loss: 0.0602 - acc: 0.9801 - val_loss: 0.4315 - val_acc: 0.8764\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 399s 20ms/step - loss: 0.0544 - acc: 0.9813 - val_loss: 0.4190 - val_acc: 0.8746\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 402s 20ms/step - loss: 0.0507 - acc: 0.9832 - val_loss: 0.4383 - val_acc: 0.8742\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 801s 40ms/step - loss: 0.0556 - acc: 0.9813 - val_loss: 0.4510 - val_acc: 0.8764\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 492s 25ms/step - loss: 0.0465 - acc: 0.9838 - val_loss: 0.5209 - val_acc: 0.8742\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 486s 24ms/step - loss: 0.0451 - acc: 0.9847 - val_loss: 0.4826 - val_acc: 0.8680\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 373,301\n",
      "Trainable params: 53,301\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(lstm_net, LSTM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 219s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85572"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = lstm_net.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_net = Sequential()\n",
    "gru_net.add(EMBEDDING)\n",
    "gru_net.add(GRU(100))\n",
    "gru_net.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 411s 21ms/step - loss: 0.1895 - acc: 0.9252 - val_loss: 0.3722 - val_acc: 0.8458\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 404s 20ms/step - loss: 0.0869 - acc: 0.9688 - val_loss: 0.3819 - val_acc: 0.8742\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 401s 20ms/step - loss: 0.0635 - acc: 0.9782 - val_loss: 0.4797 - val_acc: 0.8772\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 399s 20ms/step - loss: 0.0617 - acc: 0.9780 - val_loss: 0.4796 - val_acc: 0.8766\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 403s 20ms/step - loss: 0.0555 - acc: 0.9806 - val_loss: 0.4778 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 394s 20ms/step - loss: 0.0494 - acc: 0.9839 - val_loss: 0.5007 - val_acc: 0.8744\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 394s 20ms/step - loss: 0.0544 - acc: 0.9800 - val_loss: 0.4749 - val_acc: 0.8712\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 392s 20ms/step - loss: 0.0460 - acc: 0.9839 - val_loss: 0.5409 - val_acc: 0.8684\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 397s 20ms/step - loss: 0.0407 - acc: 0.9870 - val_loss: 0.5529 - val_acc: 0.8726\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 391s 20ms/step - loss: 0.0403 - acc: 0.9863 - val_loss: 0.5465 - val_acc: 0.8748\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 100)               39900     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 360,001\n",
      "Trainable params: 40,001\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(gru_net, GRU_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 176s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85868"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = gru_net.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1_layer_net = Sequential()\n",
    "conv_1_layer_net.add(EMBEDDING)\n",
    "conv_1_layer_net.add(Conv1D(10, 5))\n",
    "conv_1_layer_net.add(Flatten())\n",
    "conv_1_layer_net.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1403 - acc: 0.9594 - val_loss: 0.4246 - val_acc: 0.8770\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0425 - acc: 0.9874 - val_loss: 0.4676 - val_acc: 0.8758\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 25s 1ms/step - loss: 0.0207 - acc: 0.9956 - val_loss: 0.5228 - val_acc: 0.8738\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0113 - acc: 0.9978 - val_loss: 0.5727 - val_acc: 0.8750\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.6158 - val_acc: 0.8756\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 25s 1ms/step - loss: 0.0041 - acc: 0.9997 - val_loss: 0.6519 - val_acc: 0.8742\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6787 - val_acc: 0.8754\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7078 - val_acc: 0.8754\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7301 - val_acc: 0.8760\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 25s 1ms/step - loss: 9.4470e-04 - acc: 1.0000 - val_loss: 0.7556 - val_acc: 0.8758\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1296, 10)          1610      \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 12960)             0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 12961     \n",
      "=================================================================\n",
      "Total params: 334,571\n",
      "Trainable params: 14,571\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(conv_1_layer_net, CONV_1_LAYER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 8s 325us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85812"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = conv_1_layer_net.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Conv layer without backpropagation on the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1_layer_net_emb_not_train = Sequential()\n",
    "conv_1_layer_net_emb_not_train.add(EMBEDDING)\n",
    "conv_1_layer_net_emb_not_train.add(Conv1D(10, 5))\n",
    "conv_1_layer_net_emb_not_train.add(Flatten())\n",
    "conv_1_layer_net_emb_not_train.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Turn off the backprop on the embeddings\n",
    "conv_1_layer_net_emb_not_train.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 37s 2ms/step - loss: 0.1450 - acc: 0.9593 - val_loss: 0.4297 - val_acc: 0.8768\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0440 - acc: 0.9864 - val_loss: 0.4660 - val_acc: 0.8746\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0209 - acc: 0.9955 - val_loss: 0.5205 - val_acc: 0.8742\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0110 - acc: 0.9981 - val_loss: 0.5728 - val_acc: 0.8746\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.0063 - acc: 0.9992 - val_loss: 0.6119 - val_acc: 0.8740\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.6406 - val_acc: 0.8730\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 25s 1ms/step - loss: 0.0026 - acc: 0.9999 - val_loss: 0.6826 - val_acc: 0.8728\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.8730\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7374 - val_acc: 0.8722\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 9.1218e-04 - acc: 1.0000 - val_loss: 0.7611 - val_acc: 0.8726\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1296, 10)          1610      \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         (None, 12960)             0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 12961     \n",
      "=================================================================\n",
      "Total params: 334,571\n",
      "Trainable params: 14,571\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(conv_1_layer_net_emb_not_train, CONV_1_LAYER_EMB_NOT_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 8s 332us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85812"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = conv_1_layer_net_emb_not_train.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Conv layer + 1 hidden dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1_layer_1_hidden_net = Sequential()\n",
    "conv_1_layer_1_hidden_net.add(EMBEDDING)\n",
    "conv_1_layer_1_hidden_net.add(Conv1D(10, 5))\n",
    "conv_1_layer_1_hidden_net.add(Flatten())\n",
    "conv_1_layer_1_hidden_net.add(Dense(OUTPUT_DENSE_HIDDEN, activation='sigmoid'))\n",
    "conv_1_layer_1_hidden_net.add(Dropout(0.1))\n",
    "conv_1_layer_1_hidden_net.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 43s 2ms/step - loss: 0.1056 - acc: 0.9617 - val_loss: 0.4275 - val_acc: 0.8734\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0156 - acc: 0.9970 - val_loss: 0.5299 - val_acc: 0.8702\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.5834 - val_acc: 0.8712\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6616 - val_acc: 0.8718\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 5.9345e-04 - acc: 1.0000 - val_loss: 0.7034 - val_acc: 0.8730\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 3.6116e-04 - acc: 1.0000 - val_loss: 0.7406 - val_acc: 0.8720\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 2.4818e-04 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.8718\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 1.8223e-04 - acc: 1.0000 - val_loss: 0.8009 - val_acc: 0.8712\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 1.2378e-04 - acc: 1.0000 - val_loss: 0.8268 - val_acc: 0.8720\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 38s 2ms/step - loss: 9.8407e-05 - acc: 1.0000 - val_loss: 0.8488 - val_acc: 0.8716\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 1296, 10)          1610      \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 12960)             0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               1296100   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,617,811\n",
      "Trainable params: 1,297,811\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(conv_1_layer_1_hidden_net, CONV_1_LAYER_1_HIDDEN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 12s 461us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85884"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = conv_1_layer_1_hidden_net.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2_layers_net = Sequential()\n",
    "conv_2_layers_net.add(EMBEDDING)\n",
    "conv_2_layers_net.add(Conv1D(2, 20))\n",
    "conv_2_layers_net.add(Conv1D(10, 5))\n",
    "conv_2_layers_net.add(Flatten())\n",
    "conv_2_layers_net.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 88s 4ms/step - loss: 0.1322 - acc: 0.9537 - val_loss: 0.4733 - val_acc: 0.8716\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.0482 - acc: 0.9845 - val_loss: 0.5134 - val_acc: 0.8750\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 93s 5ms/step - loss: 0.0231 - acc: 0.9929 - val_loss: 0.6079 - val_acc: 0.8724\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 93s 5ms/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.6635 - val_acc: 0.8746\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 78s 4ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.7181 - val_acc: 0.8692\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 60s 3ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 0.7909 - val_acc: 0.8708\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 61s 3ms/step - loss: 0.0015 - acc: 0.9999 - val_loss: 0.8478 - val_acc: 0.8710\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 61s 3ms/step - loss: 8.6805e-04 - acc: 1.0000 - val_loss: 0.8876 - val_acc: 0.8718\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 60s 3ms/step - loss: 5.6765e-04 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.8716\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 3.8133e-04 - acc: 1.0000 - val_loss: 0.9474 - val_acc: 0.8716\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1281, 2)           1282      \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1277, 10)          110       \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 12770)             0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 12771     \n",
      "=================================================================\n",
      "Total params: 334,163\n",
      "Trainable params: 14,163\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(conv_2_layers_net, CONV_2_LAYERS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 30s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85684"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = conv_2_layers_net.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Conv Layers + 1 hidden dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2_layers_1_hidden_net = Sequential()\n",
    "conv_2_layers_1_hidden_net.add(EMBEDDING)\n",
    "conv_2_layers_1_hidden_net.add(Conv1D(2, 20))\n",
    "conv_2_layers_1_hidden_net.add(Conv1D(10, 5))\n",
    "conv_2_layers_1_hidden_net.add(Flatten())\n",
    "conv_2_layers_1_hidden_net.add(Dense(OUTPUT_DENSE_HIDDEN, activation='sigmoid'))\n",
    "conv_2_layers_1_hidden_net.add(Dropout(0.1))\n",
    "conv_2_layers_1_hidden_net.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.1037 - acc: 0.9603 - val_loss: 0.4302 - val_acc: 0.8740\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 71s 4ms/step - loss: 0.0155 - acc: 0.9959 - val_loss: 0.5374 - val_acc: 0.8698\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 67s 3ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.6610 - val_acc: 0.8742\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.6860 - val_acc: 0.8706\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 5.0863e-04 - acc: 1.0000 - val_loss: 0.7585 - val_acc: 0.8734\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 2.5013e-04 - acc: 1.0000 - val_loss: 0.8028 - val_acc: 0.8736\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 1.6304e-04 - acc: 1.0000 - val_loss: 0.8299 - val_acc: 0.8722\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 64s 3ms/step - loss: 1.2746e-04 - acc: 1.0000 - val_loss: 0.8605 - val_acc: 0.8734\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 8.9720e-05 - acc: 1.0000 - val_loss: 0.8802 - val_acc: 0.8732\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 75s 4ms/step - loss: 6.6908e-05 - acc: 1.0000 - val_loss: 0.9048 - val_acc: 0.8730\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1300, 32)          320000    \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 1281, 2)           1282      \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 1277, 10)          110       \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 12770)             0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               1277100   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,598,593\n",
      "Trainable params: 1,278,593\n",
      "Non-trainable params: 320,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_and_train_net(conv_2_layers_1_hidden_net, CONV_2_LAYERS_1_HIDDEN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 39s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85488"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = conv_2_layers_1_hidden_net.evaluate(_test_data, test_labels, verbose=1)[1]\n",
    "all_scores.append(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>emb_backprop</th>\n",
       "      <th>n_conv</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kind</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dense</th>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense</th>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense</th>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_1</th>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_1</th>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_1</th>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_2</th>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_2</th>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_hidden emb_backprop  n_conv  accuracy\n",
       "kind                                           \n",
       "dense          0          YES       0   0.86160\n",
       "dense          0           NO       0   0.86128\n",
       "dense          1          YES       0   0.86116\n",
       "lstm           0          YES       0   0.85572\n",
       "gru            0          YES       0   0.85868\n",
       "conv_1         0          YES       1   0.85812\n",
       "conv_1         0           NO       1   0.85812\n",
       "conv_1         1          YES       1   0.85884\n",
       "conv_2         0          YES       2   0.85684\n",
       "conv_2         1          YES       2   0.85488"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(nns)\n",
    "results.columns = columns\n",
    "results['accuracy'] = pd.Series(all_scores)\n",
    "results.set_index('kind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
