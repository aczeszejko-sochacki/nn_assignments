{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/janchorowski/nn_assignments/blob/nn18/assignment1/Assignment1.ipynb)"
   ]
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/janchorowski/nn_assignments/blob/nn18/assignment1/Assignment1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "P7IFJ5_Y33-8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 1\n"
      ]
    },
    {
      "metadata": {
        "id": "goqGXGZT2DKK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Important notes"
      ]
    },
    {
      "metadata": {
        "id": "-3FKET1A2GRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Submission deadline:**\n",
        "* **Problems 1-4: last lab session before or on Friday, 19.10.18**\n",
        "* **Problems 5-6: last lab session before or on Friday, 26.10.18**\n",
        "\n",
        "**Points: 10 + 4 bonus points**\n",
        "\n",
        "Please note: some of the assignments are tedious or boring if you are already a NumPy ninja. The bonus problems were designed to give you a more satisfying alternative.\n",
        "\n",
        "The assignment is in the form of a Jupyter notebook. We will be using [Google Colab](https://colab.research.google.com) to solve it. Below you will find a \"Setup\" section. Follow instructions from this paragraph to download the notebook and open it using [Google Colab](https://colab.research.google.com). \n",
        "\n",
        "Your goal is to solve problems posted below. Whenever possible, add your solutions to the notebook.\n",
        "\n",
        "Please email us about any problems with it - we will try to correct them quickly. Also, please do not hesitate to use GitHub’s pull requests to send us corrections!"
      ]
    },
    {
      "metadata": {
        "id": "1CMDOrsc2K-K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "tNjavUUC7yuM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Open the notebook using Google Colab\n",
        "\n",
        "1. From Github: Click on \"View in Colaboratory\", then save to your Google Drive.\n",
        "2. Alternatively upload manually to Drive:\n",
        "  1. Download the notebook or clone https://github.com/janchorowski/nn_assignments.\n",
        "  2. Go to  [Google Colab](https://colab.research.google.com).\n",
        "  3. Go to \"UPLOAD\" tab and select a local copy of the notebook that you downloaded in point 1.\n",
        "  \n",
        "Colab Tips:\n",
        "1. Set tab width to 4 spaces under `Tools -> Preferences`.\n",
        "  \n",
        "### 2. Open the notebook offline using Jupyter/IPython\n",
        "\n",
        "This notebook can be opened using Jupyter notebook. Simply install a scientific Python distribution on your computer (e.g. [Anaconda](https://www.anaconda.com/) or [WinPython](http://winpython.github.io/)), clone the repository https://github.com/janchorowski/nn_assignments and run `jupyter notebook`."
      ]
    },
    {
      "metadata": {
        "id": "zq_ZRu87C_OC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###   3. Install required dependencies, download data and import packages\n",
        "\n",
        "Run cells below. To run a cell either click it and click a run button or press \"shift + enter\"\n"
      ]
    },
    {
      "metadata": {
        "id": "onui8xrw5dKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please note that this code needs only to be run in a fresh runtime.\n",
        "# However, it can be rerun afterwards too.\n",
        "!pip install -q gdown httpimport\n",
        "![ -e cifar.npz ] || gdown 'https://drive.google.com/uc?id=1oBzZdtg2zNTPGhbRy6DQ_wrf5L5OAhNR' -O cifar.npz\n",
        "![ -e mnist.npz ] || gdown 'https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU' -O mnist.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YxzWq6iO2KPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Standard IPython notebook imports\n",
        "%matplotlib inline\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import httpimport\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "\n",
        "# In this way we can import functions straight from github\n",
        "with httpimport.github_repo('janchorowski', 'nn_assignments', \n",
        "                            module='common', branch='nn18'):\n",
        "     from common.plotting import plot_mat\n",
        "\n",
        "sns.set_style('whitegrid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AfmjDoxi6JNA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Follow the notebook and solve problems posted below"
      ]
    },
    {
      "metadata": {
        "id": "3hr81V8T8ccB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problems"
      ]
    },
    {
      "metadata": {
        "id": "0eT1x_VG33_E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Problem 0 [0p]\n",
        "\n",
        " \n",
        "1. To learn more about Jupyter,  read [Jupyter tutorial from Data Analysis in Biological Sciences course at Caltech](http://bebi103.caltech.edu/2015/tutorials/t0b_intro_to_jupyter_notebooks.html) (which itself can be downloaded as a Jupyter notebook). Feel free to skip the tutorial if you have some prior experience with Jupyter notebook.\n",
        "2. To learn more about basic Google Colab features, go to [Google Colab](https://colab.research.google.com) and select \"Overview of Colaboratory Features\" in \"EXAMPLES\" tab. To learn more about / set up useful keyboard shortcuts (e.g. to add a new cell without clicking \"\"+ code\"), go to \"Tools --> Keyboard shortcuts\""
      ]
    },
    {
      "metadata": {
        "id": "AsOC0voR33_F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Problem 1 [2p]\n",
        "\n",
        "First, get familiar with Python at https://docs.python.org/2/tutorial/. Then, get\n",
        "to know the capabilities of NumPy, the prime numerical library of Python http://www.numpy.org/, for instance with the tutorial at http://wiki.scipy.org/Tentative_NumPy_Tutorial.\n",
        "\n",
        "You might also need:\n",
        "  1. another intro to NumPy,\n",
        "http://people.duke.edu/~ccc14/pcfb/numerics.html\n",
        "  2. a better interactive shell for Python,\n",
        "http://ipython.org/\n",
        "  3. access to IPython through an ordinary web browser,\n",
        "http://ipython.org/notebook.html\n",
        "  4. a plotting library for Python.\n",
        "http://matplotlib.org/\n",
        "\n",
        "**a) Declare variables:**\n",
        "1. $a=10$,\n",
        "2. $b=2.5\\times 10^{23}$,\n",
        "3. $c=2+3i$, where $i$ is an imaginary unit,\n",
        "4. $d=e^{i2\\pi/3}$, where $i$ is an imaginary unit, $e$ is the Euler's number (use `exp`, `pi`)."
      ]
    },
    {
      "metadata": {
        "id": "8sd7jJhd33_G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Complete the declarations\n",
        "a = \n",
        "b = \n",
        "c = \n",
        "d = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bP0hAHvN33_K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**b) Declare vectors:**\n",
        "1. $aVec=\\begin{bmatrix} 3.14 & 15 & 9 & 26 \\end{bmatrix}$,\n",
        "2. $bVec=\\begin{bmatrix} 2.71 & 8 & 28 & 182 \\end{bmatrix}^\\intercal$ (column vector),\n",
        "3. $cVec=\\begin{bmatrix} 5 & 4.8 & \\cdots & -4.8 & -5 \\end{bmatrix}$ (vector of numbers from $5$ to $-5$ decreasing by $0.2$),\n",
        "4. $dVec=\\begin{bmatrix} 10^0 & 10^{0.01} & \\cdots & 10^{0.99} & 10^1 \\end{bmatrix}$ (logarithmically spaced numbers from 1 to 10, use `logspace` and make sure, that the result has correct length!),\n",
        "5. $eVec=Hello$ ($eVec$ is a string of characters, thus a vector)."
      ]
    },
    {
      "metadata": {
        "id": "37RmkuW533_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aVec = \n",
        "bVec = \n",
        "cVec = \n",
        "dVec = \n",
        "eVec = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C58YJtEU33_O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**c) Declare matrices:**\n",
        "1. $aMat=\\begin{bmatrix}\n",
        "                    2      & \\cdots & 2 \\\\\n",
        "                    \\vdots & \\ddots & \\vdots \\\\\n",
        "                    2      & \\cdots & 2\n",
        "                \\end{bmatrix}$,\n",
        "<br/>\n",
        "matrix $9\\times 9$ filled with 2s (use `ones` or `zeros`),\n",
        "2. $bMat=\\begin{bmatrix}\n",
        "                    1      & 0      & \\cdots &        & 0      \\\\\n",
        "                    0      & \\ddots & 0      &        & 0      \\\\\n",
        "                    \\vdots & 0      & 5      & 0      & \\vdots \\\\\n",
        "                           &        & 0      & \\ddots & 0      \\\\\n",
        "                    0      &        & \\cdots & 0      & 1\n",
        "                \\end{bmatrix}$,\n",
        "<br/>\n",
        "matrix $9\\times 9$ filled with zeros, with $\\begin{bmatrix} 1 & 2 & 3 & 4 & 5 & 4 & 3 & 2 & 1 \\end{bmatrix}$ on its diagonal (use `zeros`, `diag`),\n",
        "3. $cMat=\\begin{bmatrix}\n",
        "                    1      & 11     & \\cdots & 91     \\\\\n",
        "                    2      & 12     & \\ddots & 92     \\\\\n",
        "                    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "                    10     & 20     & \\cdots & 100\n",
        "                \\end{bmatrix}$,\n",
        "<br/>\n",
        "matrix $10\\times 10$, columns of which form the vector $1:100$ (use `reshape`),\n",
        "4. $dMat=\\begin{bmatrix}\n",
        "                    NaN & NaN & NaN & NaN \\\\\n",
        "                    NaN & NaN & NaN & NaN \\\\\n",
        "                    NaN & NaN & NaN & NaN\n",
        "                \\end{bmatrix}$,\n",
        "<br/>\n",
        "matrix $3\\times 4$ filled with `NaN`s (use... `NaN`),\n",
        "5. $eMat=\\begin{bmatrix}\n",
        "                    13  & -1  & 5  \\\\\n",
        "                    -22 & 10  & -87\n",
        "                \\end{bmatrix}$,\n",
        "<br/>\n",
        "6. $fMat$ filled with random natural numbers from $[-3,3]$ (use `rand` and `floor` or `ceil`)."
      ]
    },
    {
      "metadata": {
        "id": "Bdd1oUeI33_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aMat = \n",
        "bMat = \n",
        "cMat = \n",
        "dMat = \n",
        "eMat = \n",
        "fMat = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DqtKQi1Q33_T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** d) Declare a multiplication table ** as a $10\\times 10$ matrix `mulMat`. Use matrix/vector multiplication."
      ]
    },
    {
      "metadata": {
        "id": "OWqHq-vK33_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mulMat = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xIm6lT133_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** e) Compute elemwise using values from b).**\n",
        "For instance, the first element of $xVec[0]$ should be equal to\n",
        "\n",
        "\\begin{equation}\n",
        "1/(\\sqrt{2\\pi2.5^2}) e^{-cVec[0]^2 / (2\\cdot\\pi 2.5^2)}.\n",
        "\\end{equation}\n",
        "\n",
        "1. $xVec=1/(\\sqrt{2\\pi2.5^2}) e^{-cVec^2 / (2\\cdot\\pi 2.5^2)}$\n",
        "2. $yVec=\\sqrt{(aVec^\\intercal)^2 + bVec^2}$\n",
        "3. $zVec=\\log_{10}(1/dVec)$, using `log10`"
      ]
    },
    {
      "metadata": {
        "id": "LtH-kSU733_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xVec = \n",
        "yVec = \n",
        "zVec = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EBhf74F_33_d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** f) Compute with matrix/vector operations using values from c).**\n",
        "\n",
        "**NOTE:** Every multiplication (and power) in this subtask is a [matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication).\n",
        "1. $xMat=(aVec\\cdot bVec)aMat^2$,\n",
        "2. $yMat=bVec\\cdot aVec$\n",
        "<br/>\n",
        "(remember, that matrix multiplication is not commutative),\n",
        "4. $zMat=\\lvert cMat\\rvert (aMat\\cdot bMat)^\\intercal$, where $\\lvert A\\rvert$ denotes determinant of $A$ (use `det`)."
      ]
    },
    {
      "metadata": {
        "id": "UjdLR34u33_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xMat = \n",
        "yMat = \n",
        "zMat = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJ3xTXgV33_i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** g) Declare `ismagic(A)` function ** which checks if matrix $A$ is a [magic square](https://en.wikipedia.org/wiki/Magic_square) and returns a boolean."
      ]
    },
    {
      "metadata": {
        "id": "uCNJUx_G33_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ismagic(A):\n",
        "    # TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Es80_WJM33_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### k-Nearest Neighbors\n",
        "\n",
        "The following excerpt of code loads the data describing iris flowers\n",
        "and shows relations between their length and petal width for three\n",
        "species (namely: setosa, versicolor, virginica)."
      ]
    },
    {
      "metadata": {
        "id": "hOvm2SEE33_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "3b5eeae1-f4d9-44b1-bb70-a78723214b6d"
      },
      "cell_type": "code",
      "source": [
        "# sklearn is a large collection of machine learning algorithms\n",
        "# here we’ll use it only for the built-in iris dataset\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "print('Features: ', iris.feature_names)\n",
        "print('Targets: ', iris.target_names)\n",
        "\n",
        "petal_length = iris.data[:, iris.feature_names.index('petal length (cm)')]\n",
        "petal_width = iris.data[:, iris.feature_names.index('petal width (cm)')]\n",
        "\n",
        "for target in set(iris.target):\n",
        "    example_ids = target == iris.target\n",
        "    plt.scatter(petal_length[example_ids], petal_width[example_ids],\n",
        "                label=iris.target_names[target], color='bgr'[target],\n",
        "                marker='x', alpha=0.7)\n",
        "unknown = np.array([\n",
        "    [1.5, 0.3],\n",
        "    [4.5, 1.2],\n",
        "    [5.5, 2.3],\n",
        "    [5.1, 1.7]\n",
        "])\n",
        "plt.scatter(unknown[:, 0], unknown[:, 1], marker='v',\n",
        "            color='gray', s=50, label='??')\n",
        "plt.xlabel('petal length (cm)')\n",
        "plt.ylabel('petal width (cm)')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='upper left');"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Targets:  ['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXlclNX+xz8jMG6jIBDivuduymLK\nJqJYWnrVVBBEr7neqzcp6CdipVcJ1FDJpVRIKy3FsFwKLyqBEosI4QauqYW4AIrIPizP74+neYaB\nZ5iBWWG+79drXjDnOec83zMw5/ucc76LgGEYBgRBEITB0UrXAhAEQRC6gRQAQRCEgUIKgCAIwkAh\nBUAQBGGgkAIgCIIwUIx1LYCypKen61oEgiCIZomtrS1vebNRAID8QShDenq6Su31CRqLfkJj0U8M\nfSwNPTzTFhBBEISBQgqAIAjCQCEFQBAEYaCQAiAIgjBQSAEQBEEYKKQACIIgDBRSAARBEAYKKQCC\nIPST+HhALJYtE4vZ8qa0PXuWfTWlvxaKRh3BtmzZgvT0dFRVVWHZsmWYNGkSd83NzQ3W1tYwMjIC\nAISGhqJz586aFEdn3Lx5E61bt0afPn10LQpBNA/i44GtW4Hz54E1awChkJ2sQ0KAtDS2jqurcm0B\nduJfuZL9fdcuwN1d+f5aMBpbAaSkpODOnTuIjIxEREQEgoOD69UJDw/HwYMHcfDgQY1P/mlpoiY/\nTKjK2bNn8eDBA83fiCBaCg4OgJ0dOzmHhAAlJdLJ2s6Ova5k21ZlZcCFC9LrCQmN668Fo7EVgL29\nPUaMGAEA6NixI8rKylBdXc098WuT+Hjgu+8648mTxj9MNMSjR4/w4YcfolWrVqiursZnn32G3bt3\nIzs7G1VVVXjvvfdgbm6OI0eOwNzcHBYWFigrK8P27dthbGyMzp07IyQkBPn5+fX6MTU1hZ+fH0pL\nS1FeXo6PP/6Y+zwJosUjFLJfVsmX1NOTLbezk36JlWzbJzYWMDUF5swBBAIgI6Nx/bVgBNpICRkZ\nGYm0tDR89tlnXJmbmxtsbGyQk5MDW1tb+Pn5QSAQyO1DlWBwlZUCHDhgjRs32mHw4FL4+DzFwYOd\nufcLFz6BiUnjP4ZffvkFFRUVmDlzJu7fv4+MjAxUVVVhzpw5ePnyJT799FNs3rwZe/bswejRo2Fj\nYwM/Pz8EBgbCwsICBw4cQJ8+fVBSUiLTT1VVFUQiER4+fAh7e3tkZmbizJkzeP/995v8GRBEc6RV\nWRn6BAZy7+8HB6OmbdsmtwXQ5P6aMzoLBnfu3DlERUVh//79MuXvvfcenJ2dYWpqihUrViAmJgZv\nvvlmg32pFtDpd8TE2CAtzQybN3cFAEyYAKxZYwahsGuTeuzQoQNWrlyJDh064I033sC1a9dw5coV\nhIWFAQBatWqF4cOHw8LCAv3790e/fv3Qtm1b7iwkPz8fly5dgqenp0w/o0aNQlFRETZs2IDz589D\nLBajXbt23PgNPbiVvkJjUTOSZbqpKVc0KjZWuSf2Wm1fFBbCzNQUo2Ji2BVAU/rTE5pVMLiEhATs\n2bMH4eHh6NChg8y16dOnw8LCAsbGxnBxccHt27c1KQpMTBj4+8uW+fur9nd/9dVXceLECdjZ2WHb\ntm1ISEjA8uXLuXONM2fOQFjrBgKBALUXXJWVlRAIBPX6OX78OL755ht07twZhw8fxvr165suJEE0\nR2rv0drZAUeOyJ4J1D3Qa6Dt/eBgYORI4OhRIDISGDWqcf21YDSmAIqKirBlyxbs3bsXZmZm9a4t\nWrQI4r8/9EuXLmHAgAGaEgUAuw0UGipbFhqq2t/9l19+wZ07dzBx4kSsWrUKJiYmiI2NBQA8e/YM\n27ZtA8BO/NXV1TA1NYVAIMCjR48AAKmpqRg2bFi9fq5fv46CggL07NkTALuKqqysbLqgBNHcSEqS\nTv5r1gDt27M/JZN2UpLSbWvatgVcXKTXnZ0b118LRmNbQNHR0SgoKICvry9X9vrrr2PgwIFwd3eH\ni4sLPDw80Lp1awwZMkTh9o8qiMXAgQPWePSI/Xv7+7OTv0T5N3UF2Lt3b6xbtw7t2rWDkZERduzY\ngW+//Raenp6orq7Gyr/Nzuzs7BAUFIT27dtj48aN8PPzg7GxMXr06IG33noLt27dkunno48+QklJ\nCVavXo3//e9/8Pb2xs8//4xjx47hnXfeUfOnQxANEB/PWsjU/oKIxeyEqU6zybAwYPFiQCRi37u6\nAmVlQGam9N6Sw11F95Zcqy23uztr/in5vTH9tWSYZkJaWlqT28bFMYyzcwGzfj3DVFSwZRUVDLN+\nPcO8/TZ7vTmhymehb9BY9JO0tDT2i/H224zGvzjbtzOMlRXDuLoyTFERW1ZUxL63smKvq0CL+7uo\nsY1BeAK7ugLe3k9lnvQlyt/Pz3CVP0E0iCq2+I1h8WJgyBAgKwuYOhXIzWV/ZmWx5YsXq+c+RD0M\nQgEAgJ1dcb1tHqGQJn+CkIvkKUmiBDw9Zffl1WU5IxIBp05JlcDw4dLJ/9Qp6bYQoXYMRgEQBNEE\nhEKo3XyOD5GItdCpTWQkTf4ahhQAQRDyEYuhdvM5PoqLAQ8P2TIPD7ac0BikAAiC4EcVW/zGUFws\nu+d/7ZrsmQApAY1BCoAgCH5UscVvDBERsnv+VlayZwIREeq5D1EPUgB6wI8//oizdeOUK8DHx0fj\n3tOEgePqysZL8fOTNZ/z8wN69apvBcQXb79OWVVVFR7ev4+HJ07g4cOH7GvWLDz88EM83LsXVW3a\nsBVFIuDDD9lXLV8i3hC+yuYNUCW/gLbQsowajwWkL6Tlp2F49XAIjaSHV+JqMZKyk+Da21V3ggGY\nOXOmTu9PELzExwOxsUBhoWwY3ZUrgdOnWbPQvXvZcr54+zxlTEUFfvz2WxQAwOXLMrczj4nB8uXL\npff+8kt2tSEWyw/hq0zegA4dVMsvoC2UHYsaMYgVQPyDeHx37zuEJIRAXM1qV3G1GCEJIdiavBXx\nD+Kb1O+MGTO4sA45OTmYPn06AgMD4ePjg7lz5yI5ORkA+7S+YcMGbNiwAVlZWfDw8ICPjw8WLVqE\nly9fYufOnTh06BAAICgoCHPmzMHcuXO5J/wtW7bA09MTs2fPxvHjx2VkKCoqwooVK7h7ZmZmAgAm\nTZoEX19f/PDDD00aG0HI9QPIy2O3Z3JzpeUJCdJ2Fy6wZTwx+E1CQzEiJ4f3dsOHD4eJiUnD967r\ng6DuerpEBzIaxArAoYcDBpsNRtrjNIQkhMDfwR+hSaFIe5wGuy52cOjRtA924sSJiIuLg7e3N2Jj\nYzFx4kRUVlYiODgYz58/x4IFC3Dq1CkAwIABAzB37lwEBQVh7ty5mD59OpKTk5GXl8f1l5SUhCdP\nnuDo0aO4dOkSoqOjUVhYiDt37uDIkSMoLS3FtGnTZILDffPNN3jttdewdOlSXLt2DSEhITh06BCy\ns7Oxe/dujcdYIlow8mLyjx7NbgNt3Spb7uEBMAz7ZC8p44nB72hnh0wLC+Q/e8bdytLSEo6Ojorv\nXdcHQd31dIkOZDSIFYDQSIiF/RfCrosd0h6nwfOYJzf5r3FeI7Mt1BgmTZqEX3/9FQAQGxuLy5cv\nIzY2Fj4+Pli1ahUqKiq4gHeSZC4TJkzAl19+ibCwMFhYWKBfv35cf5mZmbCxsQHAJtTx9fXF9evX\nYW9vDwBo164d+vfvjydPnnBtrl+/jtdffx0A+wT1559/AgDatm1Lkz+hOvL8AESi+uWrVwMBAbJl\nAQFseS1M/P0xdNgwmbKhQ4dKn/4V3ZvPo1Od9XSJlmU0CAUAACatTODvIPvB+jv4N3nyB9in+tzc\nXDx+/BhFRUXo3bu33HDQkn/usWPHIioqCn379kVAQABSUlK4/oyMjFBTUyNzj7pJciQhpGtfZ2qF\nmJa0r/dlIoimIM8PoLi4fvnmzcCmTbJlmzax5XXaO9rbw9LSEgDP07+ie/Mdkqqzni7RsowGowAq\nayoRmiT7wYYmhXJnAk3F1dUV27dvh5ubG1577TXecNC1OXToEF68eIFp06ZhwYIFuHHjBndt+PDh\nuHjxIgAgKysL//3vfzFs2DCurKSkBH/99Resra1521y+fJme+gn1Ic8PIDWVtc9PTZWWjxrFeu4e\nPcrG3j9ypMEY/CahoRg6aBAAOU//yvogqLueLtGBjAahAMTVYhy4e4Db9jnyzhFuO6j2wXBTcHd3\nx88//4w333wTkydPRrt27eDp6Ynly5fzZu7p2bMnVq1ahQULFuDnn3/G1KlTuWv29vbo168fvLy8\nEBQUBE9PT9jZ2WHYsGHw9vbGu+++Cz8/P7SRmMoBmD9/PjIzMzF//nxs3boVa9eubfJYCEIGeX4A\nr7zC2udbWUnLnZ2l7Vxc2DIFMfgdAXTp0oX/6V9ZHwR119MlupBRhcikWkWlcND34xjnL5yZ9XHr\nmYoqNqxtRVUFsz5uPfP2928zcffj1CSldjD08Lb6SoscS1ycNBS0hIoKNkRz3fIzZ9iXorKKCi6U\ndIWkD777KNufgnsoHIs24sEre28F9dQdDtogrIBce7vCu683Fjov5Pb8hUZCrHFeoxd+AASht/DZ\nxguFss5ZEiSJVhSV1QrDKxQK5du/S56ITUykNv87drBPxOPGya9X5x4Kx6Jp+//G+CBoWUaD2AIC\nADtLu3oHvkIjIU3+BKFrWpItPx96LLfBKACCIPQUZfMOaCs/gbrRY7lJARAEoXtaki0/H3oqNykA\ngiB0T0uy5edDT+UmBUAQhG5pSbb8fOix3KQA1MiFCxfw/fffq6Xuvn37kJGRoS7RCEJ/aUm2/Hzo\nsdwGYQYKAKK0NDbZdO09N4kJmZpMrFxqO76oWHfp0qWqikMQuic+nrVyqf29k+QHkJiIurqyE+GQ\nIbIHvvb27GRZ20SyslJ6XfLTwYF91f4eq/m73Sjqjlme3GvW6E7GvzEMBRAfj87ffQc8eaLWWOAz\nZszA7t270bVrV+Tk5GDmzJmYOXMmvL298eGHH6Jdu3aYN28eCgsL8dVXX8Ha2hqdOnXCmDFjAAB3\n7tyBt7c3AgIC0KNHD9y6dQuDBw/Gp59+ioCAALzxxhtwcnJCQEAAcnJy0Lp1a2zZsgWlpaVYtmwZ\nSktLUV5ejo8//pgLNkcQegOf/bu8vAHh4WyZiYm07P332bLXXmPLGuMboMEY+o0ec2N8FbSMYWwB\nOTigdPBgtdvhSsJBA2w00IULF3LXbty4gdDQUIwbNw7btm3DgQMH8PnnnyNN8k9Zi8zMTHzwwQeI\niorC+fPn8fLlS+7a8ePHYWlpiSNHjmDOnDmIjY1FYWEhZs+ejYMHD+KDDz5AuOTLQxD6BJ/9u5J5\nA3jrNQffAH2TRwGGsQIQCvFk4UJ0jYlRa5ztSZMmYdOmTVw+gClTpqCwsBAA0KNHD3Tq1AnPnj2D\nSCTiIh+OHTu2Xj89e/bEK6+8AgCwsrJCUVERdy0zM5Nr89ZbbwEAEhIScPLkSXz11VcQi8Vo165d\nk+QnCI0iL769knkDeOvpe5x/fZNHAYaxAgDAmJio3Q63bjjo2hENJb8zDINWraQfc93wzgAbBlpG\n1lrhnflCRJ8+fRqdO3fG4cOHZZLDEITewWf/rmTeAN56zcE3QN/kaQCDUQCCykqN2OHWDgfNh5mZ\nGV68eIHCwkKUl5cjNTW1Uf0PHz6cyxkQFxeHPXv2oKioCD179gQAnDt3DpWSAyaC0Df47N+VzRvA\nV685+AbomzwNYBgKQCyG9YEDGrHDrR0Omg9jY2P861//gre3N/z8/DBs2DCZFYEipkyZgrKyMsyb\nNw/ffPMNZsyYAWdnZxw4cADvvvsuRowYgby8PBw7dqzJYyAIjcBn/65s3gC+es3BN0Df5FFEo2OL\n6giVQu3GxTEFzs4Ms369NNRqRQX7/u23NR4O9vTp00xBQQHDMAzz7rvvMunp6Sr11yLDDrcAaCx1\niItjv1+1v3dnzjDMq6+yL0kIZ2XL+L6zfPeoU0+rfxcl5FEFdYeDNgwFwDDMzT17dBYL/KeffmKm\nTZvGeHh4MOvXr1e5P5po9JNmNRYF8fe5sciLtc+XD0DZ+PZqivPf4D1UjKHPiyox/ZUdiwKaVT6A\nLVu2ID09HVVVVVi2bBkmTZrEXUtKSsK2bdtgZGQEFxcXrFixQpOioNjOjv/wSAt2uNOnT8f06dM1\nfh+CUApl7PPNzflt9sViYOlS4PRp4MoVYO/exse3VzZvgIJcAhzaiKGvSkx/ZXwVdOQPoLEzgJSU\nFNy5cweRkZGIiIhAcHCwzPWgoCDs3LkThw8fRmJiIu7evaspUQiCqI0S9vmtysrk2+Ln5bFeu7m5\nzcLWXS2oYt+vx74BGlsB2Nvbc96pHTt2RFlZGaqrq2FkZITs7GyYmpqiS5cuAIBx48YhOTkZ/fv3\n15Q4BEFIUMI+v8/584CpKb8t/ujRgJ8f+0TcDGzd1YIq9v167BugMQVgZGTEOShFRUXBxcWFs3fP\ny8uDubk5V9fc3BzZ2dkK+0xPT1dJJlXb6xM0Fv2kOY2l1YQJ6BMby72///cWbZ/z5wEALwoL65UB\nwP0JE1Bz61b99hMmoObaNW2I3mjU9XdRZczq+rzU+T+mcU/gc+fOISoqCvv371e5L1tb2ya3TU9P\nV6m9PkFj0U+a1Vgke9CmplzRqDNn2Kd9U1O8KCyEmampTBlXLzZWugKoW66HKwC1/V34PjNlx6xK\n21o0ZSwNKQyN+gEkJCRgz549CA8PR4daAZmsrKyQn5/PvX/69CmsrKw0KYrGqK6uxrp16+Dt7Y05\nc+YgOjoaGRkZ8PLygo+PD1asWCET24cgdI4S9vn3g4Pl2+KnpgJTp7I/m4OtuzpQxb5fj30DNKYA\nioqKsGXLFuzduxdmZmYy17p3747i4mI8fPgQVVVViIuLg6Ojo6ZEQVVVFQoKCvDw4UPeV1VVVZP7\nPnHiBIyNjfHdd99h//79CA0Nhb+/P7Zu3YqDBw/itddewzfffKPG0RCEivDFp3d2ll53cUFN27b1\nyrg49q+8AmRlAVZWehffXmOoEtPfEPMBREdHo6CgAL6+vlzZ66+/joEDB8Ld3R3r16+Hn58fANbb\ntU+fPpoSBQzDICMjA4mJifWumZubY/ny5U3ue/jw4XBycgIAiEQimJmZISAggDvgHjBgAE6fPt3k\n/glC7UhMDmvHrHd3B5YsYa173N2B9HT257hxQK9eUpNMoRDYtg0oLJSagErK9S0uf134chMoKx/f\nZ6ZsTH9V2moYjSkADw8PeHh4yL1ub2+PyMhITd1eBhMTE3Tr1g137typd2348OEyQdway4ABA7jf\nL126hNLSUm6PrqqqCt999x3efvvtJvdPEBqBz1b9/HnWRHHiRLYsNBT4/nugTRvAxgaYPBkoLgbe\neYddAXzxBSB5wNNjW3dOPmXt+OWhir+BNnwVmoBhxAIC0L9/fy4kswRLS0u1bT1dvXoV69atwxdf\nfMFZO/n5+WHQoEHkBEboP3Vs1VuVlQEFBezkX17OBmXLzWX3/rOy2JXC4sVy2+uTrXuzkE9HGIwC\nMDIywtChQ2XKhg4dqtLTf2127NiB0NBQ9O3bFwBw5coViMVi+NcNC0sQ+ohkS+LvSbJPYCBw9Sqw\nbBlgawvcvMmmVJVM/qdOASKR3Pbw9JTd99a1ZZC+y6cjDEYBAICjoyO3ClDn0z8AfPzxxxgyZAj3\nvl+/fggKClJb/wShcfji2AcGAj/8IFsWGSk7+TfUXp/i4Ou7fDrAoBSAiYkJtwpQ59M/AISFhaG8\nvJx7//vvvyMmJkZt/ROExuGLYx8cDMyeLVvm4cGeBSjTXp/i4Ou7fDrAoBQAwK4CunTponaz0+3b\nt6NNmzbcexcXF3h5ean1HgShMerYqt8PDgZGjGAtfdLTgUGDgGvX2O2frCz2LKC2EtBjW/dmIZ+O\nMDgFYGJign/+859qffoniGZPHVv1mrZtgU6d2APgNm3Y1IxWVuzev0QJRETIba9Ptu7NQj4dYXAK\nAACEBrznRxgedz9ZCXHhc5myquAg3F29VFrg6gr8+9/sxCj5fvj7Az4+wP79rAkowO79HzvGbgvV\n8vGBqysbHoIvYbufn6y5Y1hY/S2k6Oj62zNiMWu+WZv4eP6UkIrquboC773Hb4tfV77G3KeZo/FY\nQARB6I67n6yExefhyDn1C7rFp0Noao6q4CBg3Tr0YhjcBdB/8z52Qt6yhX2yNzZmvYDj44GHD4GM\nDODNN6W28zt3An/+yV6vPXEqY+seFsZuuZw4IbUkio4G5s9nVxsAq3j4bPSVteWvWw+QOnylpQEm\nJlKZ+Gzx1eEz0EwwyBUAQRgKPf024EXfrjC79wg5rrYoeXgfD4+Eg2EYCAQC9EnMkm/frwnb+cWL\nZc8RcnPZ5O+Srabnz+XfR1l5+HwaGiO3AfkM0AqAIFowQlNzdItPR46rLczuPYJ46CCYAsgZ0gM9\nOvaA0Z07rH0/UN++XxNx7EUi9h4ShSO5t60t4OjIHjTLu4+y8tSp1yc2lo3Cqazcehy/X93QCoAg\nWjhCU3NYnfpVpuyV6HgY/fijbEU++35N2M6LROy9avPDD8DatYrvo6w8qsptID4DpAAIooUjLnyO\n3KluMmV5U1xRPXOmbEU++35N2M4XF7P3qs3s2cCnnyq+j7LyqCq3gfgMkAIgiBaMuPA5t/3zom9X\nCDNvorCXNbplZYO5mIzqAQPk2/drwna+uFj2vOHaNdbHID0d2LeP3RKSdx9l5eHzaWiM3AbkM6CU\nAsjPz8fVq1dx9epVmUQuBEHoN39t/YSb/LvFp6N99z7o7rkEAoEADMPgvuMQ+fb9mrCdj4iQjSdk\nZQWsXi0NOmduLv8+ysrD59PQGLkNyGegwUPg6Oho7Nu3D3l5ebC2tgYAPH78GJ07d8bSpUsxWWIb\nTBCEZmliLPv+G3bhLlhrIKEpm4fbOPAjVAH4s/Av1gQUAEQiXNj5IRxismDs6wukp6PKyQkPC57h\namfAJjdX2un8+cDIkbB2cmq8FYnEd2DxYul5w5QpwLffsopBsu/OFy9f2bj6qsbf1+P4/epG7t8v\nICAAVVVV2LRpEwYNGiRz7ebNm4iIiMD58+exadMmjQtJEAaNinbp/TfsqldmHPgR+te+xYN4bL32\nJexs7bCmmt3iqKiqwDe3rwNXgQxcl2lvbm6O5QzTtPHUdiCTMGUK+6oNn42+snH1VY2/r6fx+9WN\n3C2giRMnIjQ0tN7kDwCDBg1CaGgoJkoSRxAEoTm0YJfu0MMBdl3skPY4DSEJISirKkNoSihy2uXw\n1lc1kRKhH8hdAUgm96dPnyImJgZFRUVgamn8lStXkgIgCG2gBbt0oZEQa5zXICQhBGmP0xD7Iham\nZqawG2IHixsWePbsGVdX3aHUCd2h8BB4yZIluHHjBiorK1FVVcW9CILQIlqwSxcaCeHvIHsPf2d/\nDBs2TKZM3aHUCd2h8AzHzMwMISEh2pCFIAh5yLNLV6NnqrhajNAk2XuEJoXCf4w/MjMzkZ+fT0//\nLQyFKwB3d3ecPHkS2dnZePToEfciCEJLaMEuXVwt5rZ/7LrYIdgmmDsTCE0JxaDB7FkgPf23LBSu\nAG7duoVTp07BzMyMKxMIBIhvYWFRCUJvqWuXXvdMQA2miUnZSdzkv8Z5Da5dviZzJuBk76SRREqE\nblGoAK5cuYJLly5RDH2C0BWurrj85DKG/GOx9HsoFEL8f37IOhGBkbUm//gH8XDo4QChkfT7Kq4W\nIyk7Ca69XSEPybXabYVGQjj0cIBDDwdM6DcBzj2dYWJiolR/GqOJ/hAEPwq3gIYNG4aKigptyEIQ\nBA/xD+LxMROLkItbIf7bRl9cLUbIxa34mIlF/IN4rt7W5K0ISQiRrZcQgq3JW7l68nDt7SqjOOIf\nxGNH6g4kZSdBXC2GUChsVH9qR+IPwRf2YevWFpesRRsoVABPnz6Fm5sbPD094e3tDS8vL3h7e2tD\nNoIgUN9Gv0RcIrNf79DDoVH11H1frWFAcfq1hcItoOXLl2tDDoIg5FDXRt/zGOsHINmvr71lo0w9\ndd9XaxhQnH5toXAF0Lt3b9y8eROjR4/G6NGjkZiYiF69emlDNoIg/obXRt/Bv94krGw9dd9XaxhI\nnH5toVABrFmzBpaWltz7gQMHIjAwUKNCEQQhizwbfclef2Prqfu+WsNA4vRrC4UKQCwWY0qtIE1T\npkyBmD5sgtAadW30j7xzRGZvvu6Br6J66r6v1jCgOP3aQql8ABcuXEB5eTlKS0sRExMDgUCgabkI\ngvibujb67YXtscZ5DTcZJ2UnNaqeuu+rNQwoTr+2UHgIHBQUhHXr1mHVqlVo1aoVRo0ahY0bN2pD\nNoIgIN9Gf43zGhl7fGXrqfu+WsOA4vRrC7krgOzsbABAr1698PXXXyMjIwPp6emIiIjgDoEldeRx\n+/ZtTJw4EYcOHap3zc3NDV5eXvDx8YGPjw+ePn2qyjgIQq+JfxDPu1+vrC39R79+hCfFT2TKjmUe\nQ+A52fO4yupKnH9wXmF/YSlhKBbL5v8tO3saOxJk99dd71RC+Ktsf8JqwPWBUmKrH1dX/gTwNPk3\niQYTwvzjH//AzJkzYWwsW626uhrHjh3DyZMneSd3ACgtLcXGjRsxduxYuTcPDw9H+/btmyg6QTQP\nJA5a5x+c58wna++vA2jwadppvxMSsxMxcOdA3PrPLfQ07YnDVw9j3vF5qGFq4BDhgKTFSTj7x1ms\njF4JCIBdk3fBvZ87733CUsIQ8lsITtw8gVNepyASilB29jQyPvRBuVU5dnwMOLYbD5w9C6xcyQqx\naxfg7t6oRDSE/iN3BRAeHo6bN2/C1dUVvr6+2Lx5MzZv3oxVq1bB1dUVt27dwr59++R2LBQKER4e\nDisrK40IThDNBVUdqr5/53u0MWqD8upyDNw5EJdyLmHhyYWoYWrQStAKY7qNQYm4BBf+vAAIADBA\nwl8Jcu+z2GYxhlgOQVZ+FqZ+PxW5xbmY9ucm/GZVDqfcNlh2tgCtysqACxekQiQkkONVC0TAMA3n\ndXv+/DmSk5Px+PFjAECXLl3g97n7AAAgAElEQVQwduxYmJubK3WDnTt3olOnTpg3b55MuZubG2xs\nbJCTkwNbW1v4+fk1eLicnp4OW1tbpe6pifb6BI1FP2loLHWfxIHGOVT9VfgXBu4ciPLqcq6stVFr\n/Nv237jz4g5XNrLzSAgEAmQ8yWjwPsXiYkz9fiqy8rO4shFmg/DzX05onXEVLwoLYWZqCowcCQgE\nQIa0v+bmeGUo/2NNaaNQAaiKPAVw/PhxODs7w9TUFCtWrMCMGTPw5ptvyu0nPT1dk2IShMYpqypD\n4O/SPftgm2C0NW6rdPvMgkwsSFzAvf/G8Rv07dC3Xp8AlLrP8/Ln8Lzgyb0/4nIElkxb9Knl53M/\nmO2vbllNW+XlJnSPPAWg0ApIU0yfPp373cXFBbdv325QAQDyB6EMhv4UoK8YylgkKwBTM1OuLLYs\ntlErgGU7l8mULU1Zin/b/lumz5gS1kxb0X0kKwBjE+kUsOVGELsCMDXlVgCjYmLYFYCptL9RsbG0\nAtARTV0ByEMpPwB1U1RUhEWLFnEOZZcuXcKAAQN0IQpBaBxVHapqb/+0MWqD1MWpaG3UGhXVFfj8\n0ucYYDYAR945gpGdR+Jo1lFEXo/EKOtRcu9Te/tniOUQXFt+DSPMBsH9aDrST+5FxagR7JP/yJHA\n0aNAZCQwahQ5XrVAlFIAhYWFyM7Olnkp4vr16/Dx8cFPP/2Eb7/9Fj4+Pjhw4ADOnj2LDh06wMXF\nBR4eHvD09IS5ubnCp3+CaK6o6lDldcyLm/xv/ecW7LvZ48C0A2glaIUapgYpOSloL2wPl14uAANA\nADj3dJZ7n4jfI7jJ/5TXKViJrHCyVwCcctvgN6ty7HXvxG7xuLhIhXB2JserlgijgA0bNjCjRo1i\n3NzcmPHjxzPjx49n3NzcFDVTO2lpaTptr0/QWHRD3P04pqKqQqasoqqCibsfxzBMw2NR1LY225O3\nM0UVRTJlY/aNYT4695FM2UfnPmJe3/e6TNmS40uYjfEbZcpO3DjBLD+1XKbss8TPmOjb0TJlpWei\nmc8vfCY7ljNn2JeM4BUME1dfbpWIi2P71cB9mtP/mCKaMpaG2ig8A0hNTUVKSgplBCMMGmVs+Tug\ng9z2fHb+QiNhvXI+G/1icTHamLTBvox9sGhvAd8xvoh/EI/LuZcxecBkNlmLkRChSaH4PvN7tDFu\nA9uutpg8YDJO3zmNd0++i/KqcvQz7wd/B3+Iq8UoEZfgi7Qv0NakLSdDW/fJeA+TZYV0d68/GHU7\nXkkSvZw/Lz1bIH8DraBwC6hPnz6UBJoweLSVHIXPRr/2fv1im8Vy5SkoK0Ab4zYoryrHpt82Ibc4\nF5t+24TyqnK0MW6DgrIC3Sd14YMSvegMuSuAzz//HADQvn17zJs3D7a2tjAyMuKur1q1SvPSEYSe\noK3kKCKhCKe8TnGT/vA9wwGA268XCUUNyrPMdhl+++s33Hx2k2tr28UWTj2dcDX3qu6TuvBBiV50\nhtwVgJGREYyMjNCtWzeMHTsWQqGQK6utCAjCUNBWchSRUITIWZEyZZGzIrnJvyF5Ap0D8cPsH2TK\nfpj9AwKdZWMG6TSpCx+U6EUnyFUAK1euxMqVKyESibjfJa+amhptykgQeoG2kqMUi4vhEeUhU+YR\n5VEveBufPMEJwZj9w2yZstk/zEZwQrBMmU6TuvBBiV50glwFkJKSgrCwMHz77bf4/PPPudfWrVsR\nGRkprxlBtEi0lRyFz0a/9pmARAnwyTPCagT2pu9F+uN0DLIYhGvLr2GQxSCkP07H3vS9GGE1QvdJ\nXfigRC86Q64C6Nu3L/r27QsAMls/bdq0wbZt27QmIEHoA9pKjsJno3/K6xSnBCJ+j5ArT6e2nbgD\n3wCnAFiJrBDgFMAdDHdq20n3SV34oEQvOkPuIbCVlRWmTZsGW1tbdOvWTZsyEYTGiH8QL5PgBGCf\nphUlOJGXHOVJ0RMsHrkYrr1dkf6Mdbn/9MKn+PPFn9g3TRotd1PCJgBAgHMAV1YsLobPjz44OPMg\nt7/vO8YXWU+z0NOsJ1cmEorg+7ov/nf3f/Ad48vJk5aThiGvDOHk8XfwR1V1FQBg8oDJ3M+DMw4i\nMy+TOy/QaVIXPijRi86QqwDc3NwajM4ZGxurEYEIQlOoGpe/7rWV0Sux/8p+/O+P/8G5tzMAdvL/\nJP4TMH/HWNw3bR82JWzCJ/GfcO0CnANQLC7GyD0jca/gHkbuGYnLyy9DJBQh+nY0frz1I/ck7+/o\nj7N/nMX/xf4fwABn/zgL937uOPvHWYT/Hg4IABMjEy72f0V1BdIepyH+QTwn7+QBkzmFIIHPB0Gn\n8E3ylOhF48jdAvr6669x4MABvPnmm/Dx8cHu3buxY8cOeHh4YOrUqdqUkSDUgrpt+TeM34Cuoq54\nVPwItnttkVOSg33p+8AwDAQCAbLys5BbnItf7vzCtfnl7i+cbf/LipcwbW2KlxUvOZv/zYmbpXb7\n5azdfsJfCVyIhwt/XmhU7H+CaAi5K4CePXsCALKysnDgwAGufOjQoVi2bJm8ZgSht6jblt+8rTnS\nl6XDdq8tHhU/wqz4WRC0EqBHxx7oYdoDd57f4WzxX+/2OiAAbj+7zZUNfWUoDs86jLlRc2Vs/vns\n9j2GeYBhGFx+epkrmzNkDhf7Xy/t+wm9R6En8LNnz/Dbb7+htLQU5eXlSE5OxqNHj7QhG0GoHXXb\n8pu3NcevC36VKYv/Zzx+nPOjTNmxOcdwbPYxmbLIWZGwFlnXs/nns9tf7bgaAU4BMmUBTgFY7bha\nbWMhDA+FsYDWr1+PLVu24Pbt22AYBgMGDMDHH3+sDdkIQu3Is+Vv6lPz87LncPvGTabM9WtX9DDt\nIVP2ztF32C2bWnhEeXArgNrM/mE2nHo6yZRtTtzMnStI2PTbpnrndKqMhTA8FK4AbGxscOTIEfz+\n++/IyMjA0aNHMXr0aG3IRhBqRd22/M/LnnPbP11FXRHlGgXr9tbIfpmN5IfJGGA+ANeWX8Or5q/i\nYs5FXHx4Ea9avMrZ9mfmZWLwrsHIzMvkbP757PZHWY9C5PVIHM06ipGdRzYq9j9BNIRcBRAUFAQA\n8PLygre3d70XQTQ31G3L/0ncJ9zkn74sHd3ad8NS26UQCARgGAZDLIfASmSFtwa8xbV5q/9bnG1/\nx9YdUVhRiI6tO3I2/6sdV0vt9tuwdvvOPZ25A1+XXi6Niv1PEA0hdwto1qxZAABfX1+tCUMQmkSe\nLb+yNvF1fQh2TdmFvwr/woIRC2De1hz3cR9rXdaiqroKlx5f4vwAApwDcO/5PfQ068n5AYiEIqQu\nScW0w9Pwv3n/42z+p7w6Bf5j2TMKf0f25/he47HRZiPuv7iPwa0H4+HDhxjcejCC7YO565KxOPRw\ngEMPB5mxKOPnQBgmchXAoEGDAAAbN26Ek5MTnJycYG9vT3kBiGaNsnH568LnQ3D2j7O4lX8LgXGB\n6NimI8xhzm69CACBQMDZ4sc/iMfj0sfoZtqNi90vrhZj58Wd6NS2E9IepXH3j38Qj8SHibDrYsfV\nraiqwI2EG0A58NWlr2TkMjc3B2PLcG13pO6AXRc7jOs9rtF+DoThofAM4MCBAxg2bBhiYmIwe/Zs\nLF68GF9//bUWRCMI/YHPh6CuLX5ZVRmvLX5j/A/46oamhCKnXQ6vXMOHD+fydWgrZwHRchAwdU0L\n5PDkyROkpqYiOjoaV65cQXJysqZlkyE9PR22trY6a69P0Fh0Q92naQAY2XkkZ4tf+KIQpmamvLb4\nfG3l2ezz1rWyg8UNCzx79owrs7S0xNKlS2USNjXmPg3RnP4uijD0sTTURuEKIDAwED4+PtiyZQuK\niorw/vvva33yJwh9gM+HQFlb/Mb4H/DWdfbHsGHDZMqGDh1aL1uftnIWEC0DhQqgtLQUACASiWBm\nZgZzc3ONC0UQ+gifD8Gm3zZhc+JmmTK+WPuNySUgr679GHtYWloCYJ/+HR0dlW5LZqEEHwoVQFhY\nGA4ePAhvb288f/4ca9asweTJkxU1I4gWBZ8PQV1b/GCbYF5b/Mb4HzRUNzQlFIMGs8YZfE//2spZ\nQLQcFCqA4uJinD9/HidPnkR0dDSKi4vh7u6uDdkIQm/g8yGoa4vf1rgtry1+Y/wPFNVFT6BLly68\nT//ayllAtCAYBbi5uTEfffQR88svvzAFBQWKqmuMtLQ0nbbXJ5r7WOLuxzEVVRUMw0jHUlFVwcTd\nj9OhVLLUllHCZ799xvxy6xeZsujb0cxniZ8xDNPwWPj6kzdmRXUrKirqtWnKfRqiuf+P1cbQx9JQ\nG4WxgCjuP6FO6trTA/UtV3Rtqy7P5j88IxxgZOPvp+aksk/dXe3QAR0A8PsVNMb/QFHdhnxxmurn\nQBgmCreACEKd1LVVl2c7r08yyovJr29yE0RjUbgCIAh1Ujcmf+yLWLm28/oiY0Mx+fVJboJoLHIV\ngCJb/7Fjx6pdGMIwkNiqSyZRQP9s1flklNj767PcBNEY5CqAL774Qm4jgUBACoBoMuqOya8J+GTk\ni8mvb3ITRGOQqwAOHjwot1FMTIxGhCFaPnVt1Sf0nYDYslhuv10fJtO6Mvo7+GNz4mZEXo8EBGwq\nxgCnAIQmhcrITRDNDYVnAI8ePcKhQ4dQUFAAABCLxbh48SLeeOMNjQtHtDzq2qpfu3xNZr9dH8IW\n15VRaCSEc09nRGZGysTkryu3xAqIIJoLCq2A/u///g9mZma4fPkyhg0bhoKCAmzZskUbshEtENfe\nrvAb6yfzpC85dPUb66dw8g9LCUOxuFimrFhcjLCUsCbXjX8QL+Ml69rbFe+Nfk8m9r97P3fsmrwL\nu6bsgns/d05uhx4OeG/0ezJyn/3jLM7+cVbmHuJqMeIfxDc4NoLQNgoVgJGREZYuXQpLS0t4e3vj\nyy+/xHfffadU57dv38bEiRNx6NCheteSkpIwa9YseHh4YPfu3Y2XnGi2uPZ25Q2WpszkH/JbCKZ+\nP5Wb2IvFxZj6/VSE/BYiM7ErW1di8183dENSdhJ2pO6QmbTd+7lzk7+k7Y7UHUjKTuLanv3jLFZG\nr8TK0ys5JSDZUtqavJWUAKFXKFQAFRUVePLkCQQCAbKzs2FsbIycHP7Y5LUpLS3Fxo0b5R4WBwUF\nYefOnTh8+DASExNx9+7dxktPGBSLbRZjiOUQZOVnYer3U5FbnIup309FVn4WhlgOwWKbxY2uq0oM\nfT6fhro5AshfgNBnFJ4BLF68GMnJyVi0aBH+8Y9/wMjICG+//bbCjoVCIcLDwxEeHl7vWnZ2NkxN\nTdGlSxcAwLhx45CcnIz+/fs3YQiEoSASinDK6xQ3kQ/fMxwAMMRyCE55neLSKjamrjybf2Xs++X5\nNMwZMofLEUD+AoQ+o1AB9OnTB/369QMApKamoqSkBPfv31fcsbExjI35u8/Ly5MJK21ubo7s7GyF\nfaanpyuso8n2+oQhjyVwQCA8H3vKvL917ZZKdSe0nYDYF9KwJxP6TsC1y9eUkqd228IXhXijL2sg\nEf8ivkn96QuG/D+mz6hzLHIVwMuXL/HixQsEBgYiNFRqD11ZWYnVq1frxBSUMoKxGPJYJPv4xibS\nf93gO8H1VgCNqSvZozc1M+XKYstilXpir91WkhEspiQGAoGgSf3pC4b8P6bPNDUjmDzkngFkZGRg\n/fr1uHHjBhYsWMC9li5dqrITmJWVFfLz87n3T58+hZWVlUp9Ei0fyYQu2ce/tvyazD5/bYsfZeuq\nEkO/bttgm+B6OQIoJj+hz8hVAOPGjcP+/fuxZs0a/Prrr9zr3LlzWL9+vUo37d69O4qLi/Hw4UNU\nVVUhLi6ON745QdQm4vcIbkI/5XUKViIrnPI6xU3sEb9HNLquKjH067Zta9y2Xo4AislP6DWKYkkX\nFBQwmzZtYvz9/RmGYZjY2Fjm2bNnCmNQX7t2jZk3bx4zfvx4xt3dnZk3bx6zf/9+5syZMwzDMExq\naiozZ84cZs6cOUxERIRKMa2VwdBjgusrjR3L9uTtTFFFkUxZUUURsz15e5PrqhJDny+3wZm7Z5gz\nd880qT99wZD/x/QZrecD+Pjjj2Fvb4+MjAwArCfw6tWrea17ajNs2LAGw0nY29sjMjKykeqKMHR8\nx/jWKxMJRbzlytZVJYY+X53avgKN7Y8gtIlCP4Dnz59j/vz5XP7RN998E+Xl5RoXjCAIgtAsSiWE\nqayshEAgAADk5+ejtLRUo0IRBEEQmkfhFtC8efMwa9Ys5OXlYfny5bh27RrWrl2rDdkIgiAIDaJQ\nAUyePBmjRo1CRkYGhEIhNmzYQCabBEEQLQCFCqCkpATnzp3D3bt3IRAIkJeXh+nTp6NNmzbakI8g\nCILQEAoVwAcffABTU1PY2NiAYRikpaXhwoULDWYMIwiCIPQfhQqgsLAQe/fu5d7PnTsXXl5eGhWK\nIAiC0DwKrYC6d++OvLw87n1+fj569eqlUaEIgiAIzaNUSkh3d3f0798fNTU1uH//Pvr16wdvb28A\nUDo5DEEQBKFfKFQAvr71vSkJgiCI5o9CBTB69GhtyEEQBEFoGaU8gQmCIIiWBykAgiAIA4UUAEEQ\nhIFCCoAgCMJAIQVAEARhoJACIAiCMFBIARAEQRgopAAIgiAMFFIABEEQBgopAIIgCAOFFABBEISB\nQgpAQ8THA2KxbJlYzJYTBEHoA6QANEB8PLB1KxASIlUCYjH7futWUgIEQegHpAA0gIMDYGcHpKWx\nk35JCfszLY0td3DQtYQEQRCkADSCUAisWSNVAp6e0sl/zRr2OkEQhK4hBaAhhELA31+2zN+fJn+C\nIPQHUgAaQiwGQkNly0JD6x8MEwRB6ApSABpAcuAr2fY5ckT2TICUAEEQ+gApAA2QlCS759++veyZ\nQFKSriUkCIJQIicw0XhcXdmfDg7SPX+hkH3v4CC9DrCrgaQk2TKCIAhtoFEFEBwcjCtXrkAgECAw\nMBAjRozgrrm5ucHa2hpGRkYAgNDQUHTu3FmT4miVuhN6fDywYwe7Chg3jlUItbeK+NoQBEFoEo0p\ngNTUVPz555+IjIzEH3/8gcDAQERGRsrUCQ8PR/v27TUlgl7h4ACcPy89B/D3Zw+FyTeAIAhdobEz\ngOTkZEycOBEA0K9fPxQWFqK4uFhTt9N7yDeAIAh9Q2MrgPz8fAwdOpR7b25ujry8PIhEIq5s3bp1\nyMnJga2tLfz8/CAQCBrsMz09XSWZVG2vDiZMaIXY2D613t/HtWs1je5HH8aiLmgs+gmNRT9R51i0\ndgjMMIzM+/feew/Ozs4wNTXFihUrEBMTgzfffLPBPmxtbZt8//T0dJXaqwPJnr+pqbQsNnZUo1cA\n+jAWdUFj0U9oLPpJU8bSkMLQ2BaQlZUV8vPzufe5ubl45ZVXuPfTp0+HhYUFjI2N4eLigtu3b2tK\nFL2AfAMIgtA3NKYAHB0dERMTAwDIzMyElZUVt/1TVFSERYsWQfz3rHfp0iUMGDBAU6LoBeQbQBCE\nvqExBWBjY4OhQ4fC09MTQUFBWLduHX788UecPXsWHTp0gIuLCzw8PODp6Qlzc3OF2z/aRtl4/itX\nAs+fy5Y9fw7MmCHb3tWVNf8cPVrWN8DPD5gwQdYElHIJEAShDTR6BuBfJxraoEGDuN8XLFiABQsW\naPL2TUYSz//8eamFDp/N/sqVQHg48MsvQHo6YG7OTv5DhgC5uYCTE/Dbb2z7s2fZugBgbAy4u7N9\nbt3K9jlyJNunMvfu0EH7nwlBEC0PCgXBg7Lx/DdsALp2BR49Amxtgfv32Z8FBexBb6dO0vYJCdL+\nL1yQ3yflEiAIQltQKAgeJDb7konX05Mtr2uzb27OPvnb2rJKQLLA6doVSE4G9u6Vbe/hATAMcPmy\n/D6VvTdBEISq0ApADsrG8zc3B379Vbbs118Ba+v67VevBgICFPdJuQQIgtAGpADkoGw8/+fPATc3\n2TI3N+DJk/rtN28GNm1S3CflEiAIQhuQAuBBWZv958+l2z9duwI3b0rPBAYPZk07Je1HjQIiI4Gj\nR9kDX3l9kr8AQRDaghQAD8ra7H/yiXTyT08H+vRhf3bqBBQWsofBkvbOztL+XVzk90n+AgRBaAs6\nBObB1RWIigL+8x/Zw9m//gKsrKQ2+2FhVXjy5AnMzYHSUvYFADEx7KQdFWUNoZD9iN3dgSVLgKFD\n2d8lffr5ARER0j7l5RJYs0aaN6AFhTUhCEKHkALgISwM+OEHIDMTOHUKEImApUuBAwcAgQDo2xdY\nuxb4+WcG3bv/iE6dCvDVV7J9vPaaOZKTl2PCBPZ9fDxr219Swjp+Sez76/oBAPx5AYRCyhdAEIR6\noS0gHhYvZp25srKAqVNZp66sLHbyZxhg3z7W5t/X1wRXrozg7aNNm+Fwdjbh3pN9P0EQ+gatAHgQ\nidgn/6lT2Yl/+HC2fOxYIDubtfCR2PwbGTmiujoTRkb5tXqwhL+/o4zZJtn3EwShb9AKQA4iEWu1\nU5sff6wfj+fcORM4OQ2VKXNwGIr27U1QF7LvJwhCnyAFIIfiYtZztzYzZ9bfhx8/Hvj1V0eUlloC\nAEpLLZGU5Mhrrkn2/QRB6BOkAHgoLpZu/wwZAly7BgwYwIZ3yM5mvXxv3gS6dAEePgR27DCBiQm7\nCmjXbijS0kzq2eyTfT9BEPoGKQAeIiKkk/+pU6zp55Ah7AGwQMBaBPXpA+zYIbXmefbMEV26dIG/\nvyOvzT7Z9xMEoW/QITAPvr7sz8WL2bMAgLX8AYBevVgTUACYNo19kj99GvjySxOIxf+EUGgiY7Mv\nQRn7foIgCG3SolcAyiZWCQtjt31qc+5c/f3648fZ8tq8/z7rNAYAwr9n9r/+AiZPZn/W5vFj5SZ6\nSghDEIQ2aLErgLqJVQD+pC5hYWzZiRNSp6+332aTvERHs/XWr2e3gfLy2H7Hjwfi4oB+/YB799g6\nr7zCXr97lz0vANjVwp9/Aj17AocPA/PmATU17CogKYlfHkoIQxCEtmixK4C6jldlZa14Ha/4nL6e\nPZM6fYWFsR7BkjAPADtJnzghnfwBts2FC2wQuNoMHAhcugQsXMhO/q1aAWPGUEIYgiB0T4tVAJL9\ndclkGhjYR+YQVrIPL3H6kiiB4cPZif3119msXi9fsmWlpezBrYTp06W/S5TFuHFAVRWb8jE+HmjT\nBigvZ/MAV1QArVsDq1YBd+6wjmB88tSVW149giAIVWmxCgBQ3vGKz+nrxAkgMVG27OJF9hygNseP\n19+bj41llcGFC7LlCQnAxo2K5SGHMYIgtEGLVgDKOl7xOX394x+Ao6Ns2euvyz75A+z7uge7Eyaw\ne/guLrLlzs7Axx8rloccxgiC0AYtVgHUdbwKDr7P63jF5/TVty/7tF9YCHTsyJa1a8fux0uovRKQ\n+AecP89u/1RVsUqhvJzdBkpNZbd/KiqAzz9nD4kpIQxBELqmxSqAuo5XbdvW8Dpe8Tl9WVhIJ3Vf\nXzaGf7t20r5dXdkVQt++0jILC/aJ/8YNWTlu3QLs7dlQ0q1asQfBKSmUEIYgCN3TYs1A5TleOTiw\nL8l1X1/2iX3IEKnT188/s6agdnasCSjAWgeZmrJx++Pi2LI//gDatgWMjFgTUADo3589O3ByAh48\nYE1AAWDuXPbnzp3SSZzPEYwSwhAEoS1a7AoAYCfL2gen8fFs+AaJDT7A/iwpAb78UvYw9+efpZO/\npK2LC5vwXdJ22jR2m6eiQuoM9uQJ8NZb7O+rVsnKM3du/Sd4vkQvdeWWV48gCEIVWrQCqIsqNvZ8\nbQcOlO75L17M+gsMHsyeHZiaskqFIAhCXzEoBaCKjT1f25s32S2k2v4Cksn/xg02aihBEIS+YlAK\nAFDNxp6v7fr19f0FfvuNJn+CIPQfg1MAqtjY87Vdv76+v4CTE3sWQBAEoc8YlAJQxcaer+2gQWys\noNr+Aqam7PvBg0kJEASh3xiUAlDFxp6v7a1b0tg/ERGsv8CNG1Il8K9/aW9sBEEQjaXF+gHwoUpS\nFr62J0+ypqDz5wOzZrFl1tasEvjXv4CfftLAIAiCINSERhVAcHAwrly5AoFAgMDAQIwYMYK7lpSU\nhG3btsHIyAguLi5YsWKFJkXh4JvklbWx56tz8mT9MmtrmvwJgtB/NLYFlJqaij///BORkZH49NNP\n8emnn8pcDwoKws6dO3H48GEkJibi7t27mhKFIAiC4EFjCiA5ORkTJ04EAPTr1w+FhYUo/jvvYnZ2\nNkxNTdGlSxe0atUK48aNQ3JysqZEIQiCIHjQ2BZQfn4+hg4dyr03NzdHXl4eRCIR8vLyYG5uLnMt\nOztbYZ/pKgbBUbW9PkFj0U9oLPoJjYUfrR0CMwyjch+2trZNbpuenq5Se32CxqKf0Fj0E0MfS0MK\nQ2NbQFZWVsjPz+fe5+bm4pVXXuG99vTpU1hZWWlKFIIgCIIHja0AHB0dsXPnTnh6eiIzMxNWVlYQ\n/R1vuXv37iguLsbDhw9hbW2NuLg4hNZ1seWBtoCk0Fj0ExqLfkJj4UfAqGNvRg6hoaFIS0uDQCDA\nunXrkJWVhQ4dOsDd3R2XLl3iJv1JkyZh0aJFmhKDIAiC4EGjCoAgCILQXwwqFARBEAQhhRQAQRCE\ngUIKgCAIwkAhBUAQBGGgkAIgCIIwUAxCAdy+fRsTJ07EoUOHdC2KymzZsgUeHh545513cObMGV2L\n02TKysqwatUqzJs3D7Nnz0ZcXJyuRVKZ8vJyTJw4ET/++KOuRWkyFy9exJgxY+Dj4wMfHx9s3LhR\n1yKpxMmTJzFt2jTMnDkT8fHxuhanyfzwww/c38THxwejRo1SS78tPh9AaWkpNm7ciLFjx+paFJVJ\nSUnBnTt3EBkZiYKCAsyYMQOTJk3StVhNIi4uDsOGDcOSJUuQk5ODd999F+PHj9e1WCrx5ZdfwtTU\nVNdiqMzo0aOxY8cOXffIQZkAAAiiSURBVIuhMgUFBdi9ezeOHTuG0tJS7Ny5E67KxH3XQ2bPno3Z\ns2cDYCMtnz59Wi39tngFIBQKER4ejvDwcF2LojL29vZcToWOHTuirKwM1dXVMDIy0rFkjWfKlCnc\n748fP0bnzp11KI3q/PHHH7h7926znWBaIsnJyRg7dixEIhFEIlGzX81I2L17t1KRE5ShxW8BGRsb\no02bNroWQy0YGRmhXbt2AICoqCi4uLg0y8m/Np6envD390dgYKCuRVGJzZs3IyAgQNdiqIW7d+9i\n+fLlmDt3LhITE3UtTpN5+PAhysvLsXz5cnh5ebWIkPNXr15Fly5duLhqqtLiVwAtkXPnziEqKgr7\n9+/XtSgqc+TIEdy4cQMffvghTp48CYFAoGuRGs3x48cxcuRI9OjRQ9eiqEzv3r2xcuVKTJ48GdnZ\n2Zg/fz7OnDkDoSQPajPjxYsX2LVrFx49eoT58+cjLi6uWf6PSYiKisKMGTPU1h8pgGZGQkIC9uzZ\ng4iICHTo0EHX4jSZ69evw8LCAl26dMHgwYNRXV2N58+fw8LCQteiNZr4+HhkZ2cjPj4eT548gVAo\nhLW1NRwcHHQtWqPp3Lkztz3Xs2dPWFpa4unTp81SuVlYWGDUqFEwNjZGz5490b59+2b7Pybh4sWL\n+Oijj9TWX4vfAmpJFBUVYcuWLdi7dy/MzMx0LY5KpKWlcSuY/Px8lJaWolOnTjqWqmmEhYXh2LFj\nOHr0KGbPno1///vfzXLyB1irma+++goAkJeXh2fPnjXb8xknJyekpKSgpqYGBQUFzfp/DGDD5rdv\n316tq7EWvwK4fv06Nm/ejJycHBgbGyMmJgY7d+5slhNodHQ0CgoK4Ovry5Vt3rwZXbt21aFUTcPT\n0xNr166Fl5cXysvL8cknn6BVK3oe0TVubm7w9/dHbGwsKisrsX79+ma7/dO5c2e88cYbmDNnDgDg\no48+atb/Y3UzKaoDigZKEARhoDRfdUgQBEGoBCkAgiAIA4UUAEEQhIFCCoAgCMJAIQVAEARhoJAC\nIFoc58+fx4sXLxqs4+Pjg6SkJJmyixcvYu7cuWqX58SJEwDY0AQuLi5Ktdm1axdnj98UXr58CU9P\nTzx9+rTJfRAtH1IARIvj66+/RmFhoa7FAABUV1fjiy++aFSbq1evIjExEYsWLWryfTt27IiVK1di\n7dq1Te6DaPm0eEcwonlz8eJFhIWFoWvXrsjJyUGHDh2wfft2iEQiREdH49ChQ2AYBubm5ggKCsLp\n06eRlpYGf39/hISE4P79+4iIiIBQKER1dTW2bNmC7t27K7zvo0eP8N///hdlZWUoLS3FBx98AAcH\nBwQEBMDKygq3b9/G/fv3MWvWLCxZsgQFBQXw8/NDaWkpevfujUePHmH58uU4ceIEF+56w4YNAIDt\n27fj0qVLKC0txd69e+t52n755Zf45z//CQCoqalBUFAQrl+/DgBYuHAhJk+eDDc3N3h6eiIhIQF5\neXlYvXo1IiMjcffuXaxYsQIzZsyAk5MTPvvsM9y4cQODBw9W7x+GaBkwBKHHpKSkMMOHD2eePHnC\nMAzD+Pv7M9988w3z6NEjZurUqUxFRQXDMAzz9ddfMyEhIQzDMMz48eOZBw8eMAzDMFFRUUxOTg7D\nMAyzZ88eZtOmTQzDMMy8efOYxMTEevfy9PRkGIZhlixZwiQnJzMMwzC5ubnM+PHjmcrKSmb16tWM\nr68vwzAM8/DhQ8bGxoZhGIbZtm0bExwczDAMw9y6dYsZOnQok5iYyGRnZzPOzs4MwzBMdnY2M3jw\nYObWrVsMwzBMYGAg89VXX8nIUFVVxYwcOZIpKipiGIZhfvrpJ+Y///kPwzAMU1hYyCxZsoSpqqpi\nxo8fzxw9epRhGIZZvXo1s2DBAqampoZJSUlhpk2bxvW3adMmZu/evU367ImWD60ACL2nf//+3FOy\njY0Nbty4AUtLS+Tl5XHbJGKxmPfJ3tLSEqtXrwbDMMjLy1M6k9LFixdRUlKC3bt3A2DDij979gwA\nmzAFALp164bi4mJUV1fj5s2bXMiBV199FX369OHtt1OnTnj11VcBANbW1nj58qXM9RcvXsDExAQi\nkQgAux30+uuvA2C3dfbt28fVtbGxAcCGPOjcuTMEAgGsra1RVFTE1enWrRtu376t1JgJw4MUAKH3\nMLWilTAMA4FAAKFQiBEjRmDv3r1y21VWVsLX1xc//fQTevfujUOHDnFbKYoQCoXYuXMnb+wVY2PZ\nrw3DMKipqZGJMyMv5kzd/A2MgkgsAoEANTU1vNdqy1FXJoJQBjoEJvSee/fuITc3FwCQnp6OgQMH\nYvjw4bh69Sry8vIAAKdPn8a5c+cAsJNmVVUVSkpK0KpVK3Tr1g0VFRWIjY2FWCxW6p62trZc2r3n\nz5/j008/bbB+3759kZGRAYBNqHLv3j0ArCKoqqpSeqxmZmaorKxEcXExAGDUqFFISEgAABQXF2P2\n7NlKjwEAcnJylDrzIAwTUgCE3tO/f39s27YNc+fORUlJCaZPn47OnTtj7dq1WLZsGby9vREVFYWR\nI0cCYMMAL1++HPfu3cPbb7+NWbNmwdfXF4sWLUJKSopS+VTXrl2Lc+fOwcvLC0uXLsWYMWMarL9w\n4UKkpKTAy8sL3377LYYOHQojIyNYWVnB0tISM2fORFlZmcL7GhkZYcyYMZyJ6uTJk9G9e3d4enpi\n4cKFWLhwYaOicyYnJ8PZ2Vnp+oRhQdFACb1GYgV0+PBhXYvSIPfu3UN2djbGjRuH8vJyTJw4EVFR\nUbC2tm50X1evXkVISIjKY05MTMSBAwcQERGhUj9Ey4VWAAShBjp06ICvv/4aHh4e8Pb2xtKlS5s0\n+QPAiBEj4OjoqLIj2M6dOxVuXRGGDa0ACIIgDBRaARAEQRgopAAIgiAMFFIABEEQBgopAIIgCAOF\nFABBEISB8v8hOBrNMnuovAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8ce9a6ca90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "s2khewKZ33_w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Based on these two features, it is easy to distinguish iris setosa from the two remaining species. Yet iris versicolor and virginica remain mixed together. \n",
        "\n",
        "Looking closely at the plot, we might estimate the species of the selected unknown irises (gray triangles). For three of them the answer seems obvious – they belong in uniformly-colored areas covered by one species only. Yet unknown iris flower in (5.1, 1.7) is troublesome – it lays on the boundary of versicolor and virginica clusters. We can assume, that its species is the one of the closest one to it, coming from the training set (and so having a label). \n",
        "\n",
        "K-Nearest Neighbors method (http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) solves the classification problem, i.e. sets class labels (species in case of irises) of a previously unseen sample by choosing the most common class among the top k neighbors of the sample in question (for instance according to the Euclidean distance). Thus, the k-Nearest Neighbors algorithm works as follows. For each unlabeled sample x:\n",
        "1. Find k nearest neighbors among the labeled samples.\n",
        "2. Set the most common label among them as label of x."
      ]
    },
    {
      "metadata": {
        "id": "8-G-sMUw33_x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Problem 2 [2p]\n",
        "\n",
        "1.  **[1p]** Load the iris data (in Python it’s built-in into machine learning libraries, use sklearn.datasets.load_iris), the data is also available on-line at https://archive.ics.uci.edu/ml/datasets/Iris\n",
        "\n",
        "2.  **[1p]** Irises are described with 4 attributes: petal and sepal widths and lengths. We often plot such data as matrices depicting relationships between pairs of attributes (the diagonal of which holds an ordinary histogram). Write code making a plot like the one below. Please pay attention to the details: make a proper legend and correctly label the axes.\n",
        "\n",
        "<img src=\"https://github.com/janchorowski/nn_assignments/blob/nn18/assignment1/iris4x4.png?raw=1\"/>"
      ]
    },
    {
      "metadata": {
        "id": "F6sG0bxf33_y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Problem 3 [2p]\n",
        "\n",
        "Implement the k-Nearest Neighbors algorithm. Try to\n",
        "take advantage of matrix calculus rather than using for loops.\n",
        "\n",
        "**Tip:** What is computed by \\begin{equation} \\sqrt{(X - Y)^T (X - Y)} \\end{equation} when both X and Y are vectors?\n",
        "\n",
        "**Tip:** Try to use broadcasting (NumPy: http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) and built-ins sort, numpy.sort, numpy.argsort (sorting), scipy.stats.mode (choosing the most common element of the set)."
      ]
    },
    {
      "metadata": {
        "id": "1iZtHs5A33_z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Problem 4 [2p]\n",
        "Consider the following experiment:\n",
        "1. We scramble the data and split it into two parts - training set (66.6% of all samples) and test set (33.4%).\n",
        "2. Based on the training set, we use the k-NN algorithm to predict the labels on the test set.\n",
        "3. We then check the number of errors and write it down.\n",
        "\n",
        "Do this 500 times for k ∈ {1, 3, 5, ..., 19}. Plot a function of the average number of errors\n",
        "as the function of k. It should be similar to the one below.\n",
        "\n",
        "<img src=\"https://github.com/janchorowski/nn_assignments/blob/nn18/assignment1/knn.png?raw=1\"/>"
      ]
    },
    {
      "metadata": {
        "id": "A86GnZpa33_0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Problem 5 [2p] \n",
        "\n",
        "Apply the K-Nearest Neighbors (K-NN) algorithm to the MNIST and CIFAR10 datasets. \n",
        "\n",
        "The MNIST (http://yann.lecun.com/exdb/mnist/) dataset consists of normalized (centered and stretched) scans of hand-written digits. Specifically, each element of the dataset is a 28 × 28 grayscale image, thus having 764 8-bit pixels. \n",
        "\n",
        "The CIFAR10 (http://www.cs.toronto.edu/~kriz/cifar.html) dataset consists of small, 32 by 32 pixels, RGB images belonging to 10 categories.\n",
        "\n",
        "1. **[1p]** Download and load the MNIST and CIFAR10 datasets. For both datasets, display a few objects from each of the classes, paying attention to aesthetics and clarity of your presentation. **Note:** You already downloaded the datasets in \"Setup\" section. Please use the code below to get started.\n",
        "\n",
        "2. **[2p]** Apply a k-NN classifier to the MNIST and CIFAR10 datasets. First, divide the training set into two parts, which we will call training and validation. On MNIST use the first 50000 samples for training and the last 10000 for validation. On CIFAR10, use 40000 to train and 10000 for validation. Then find the optimal number of neighbors by assessing the accuracy on the validation set. You do not need to repeat this experiment multiple times. Finally, compute the accuracy on the test set obtained with the best previously chosen number of neighbors. On MNIST you should get about 3% errors, while on CIFAR10 you should get about 70% errors. Why CIFAR10 is harder than MNIST? Pick a few mislabeled samples from the test dataset and plot them along with the correct ones. **Note:**\n",
        "  * MNIST and CIFAR10 are much larger than the Iris dataset. A good implementation may need a few minutes depending on your runtime type. Please optimize your algorithm:\n",
        "  * Compute the distances only once, then test for different values of k.\n",
        "  * Use vectorized expressions to compute the distance. It is possible to compute all distances between the training and testing points in one expression. Hint: think about the vectorized expression \\begin{equation}(X - Y)^T (X - Y)\\end{equation}.\n",
        "  * You can use single precision numbers in computation.\n",
        "  * If your code is taking a long time to execute, please save its results before the lab session.\n",
        "\n",
        "**Note:** in NumPy, matrices have its own data type (dtype), which is retained during\n",
        "calculations. Please pay attention to it. I particular, do not subtract values of data types not\n",
        "having the sign bit, do not divide integers, etc. Results of such operations will not be\n",
        "automatically casted to types having the required precision."
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P7IFJ5_Y33-8"
   },
   "source": [
    "# Assignment 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goqGXGZT2DKK"
   },
   "source": [
    "## Important notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-3FKET1A2GRK"
   },
   "source": [
    "**Submission deadline:**\n",
    "* **Problems 1-4: last lab session before or on Friday, 19.10.18**\n",
    "* **Problems 5-6: last lab session before or on Friday, 26.10.18**\n",
    "\n",
    "**Points: 10 + 4 bonus points**\n",
    "\n",
    "Please note: some of the assignments are tedious or boring if you are already a NumPy ninja. The bonus problems were designed to give you a more satisfying alternative.\n",
    "\n",
    "The assignment is in the form of a Jupyter notebook. We will be using [Google Colab](https://colab.research.google.com) to solve it. Below you will find a \"Setup\" section. Follow instructions from this paragraph to download the notebook and open it using [Google Colab](https://colab.research.google.com). \n",
    "\n",
    "Your goal is to solve problems posted below. Whenever possible, add your solutions to the notebook.\n",
    "\n",
    "Please email us about any problems with it - we will try to correct them quickly. Also, please do not hesitate to use GitHub’s pull requests to send us corrections!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CMDOrsc2K-K"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNjavUUC7yuM"
   },
   "source": [
    "### 1. Open the notebook using Google Colab\n",
    "\n",
    "1. From Github: Click on \"View in Colaboratory\", then save to your Google Drive.\n",
    "2. Alternatively upload manually to Drive:\n",
    "  1. Download the notebook or clone https://github.com/janchorowski/nn_assignments.\n",
    "  2. Go to  [Google Colab](https://colab.research.google.com).\n",
    "  3. Go to \"UPLOAD\" tab and select a local copy of the notebook that you downloaded in point 1.\n",
    "  \n",
    "Colab Tips:\n",
    "1. Set tab width to 4 spaces under `Tools -> Prferences`.\n",
    "  \n",
    "### 2. Open th enotebook offline using Jupyter/IPython\n",
    "\n",
    "This notebook can be opened using Jupyter notebook. Simply install a scientific Python distribution on your computer (e.g. [Anaconda](https://www.anaconda.com/) or [WinPython](http://winpython.github.io/)), clone the repository https://github.com/janchorowski/nn_assignments and run `jupyter notebook`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zq_ZRu87C_OC"
   },
   "source": [
    "###   3. Install required dependencies, download data and import packages\n",
    "\n",
    "Run cells below. To run a cell either click it and click a run button or press \"shift + enter\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onui8xrw5dKi"
   },
   "outputs": [],
   "source": [
    "# Please note that this code needs only to be run in a fresh runtime.\n",
    "# However, it can be rerun afterwards too.\n",
    "!pip install -q gdown httpimport\n",
    "![ -e cifar.npz ] || gdown 'https://drive.google.com/uc?id=1oBzZdtg2zNTPGhbRy6DQ_wrf5L5OAhNR' -O cifar.npz\n",
    "![ -e mnist.npz ] || gdown 'https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU' -O mnist.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxzWq6iO2KPm"
   },
   "outputs": [],
   "source": [
    "# Standard IPython notebook imports\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import httpimport\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "# In this way we can import functions straight from github\n",
    "with httpimport.github_repo('janchorowski', 'nn_assignments', \n",
    "                            module='common', branch='nn18'):\n",
    "     from common.plotting import plot_mat\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfmjDoxi6JNA"
   },
   "source": [
    "### 4. Follow the notebook and solve problems posted below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hr81V8T8ccB"
   },
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eT1x_VG33_E"
   },
   "source": [
    "### Problem 0 [0p]\n",
    "\n",
    " \n",
    "1. To learn more about Jupyter,  read [Jupyter tutorial from Data Analysis in Biological Sciences course at Caltech](http://bebi103.caltech.edu/2015/tutorials/t0b_intro_to_jupyter_notebooks.html) (which itself can be downloaded as a Jupyter notebook). Feel free to skip the tutorial if you have some prior experience with Jupyter notebook.\n",
    "2. To learn more about basic Google Colab features, go to [Google Colab](https://colab.research.google.com) and select \"Overview of Colaboratory Features\" in \"EXAMPLES\" tab. To learn more about / set up useful keyboard shortcuts (e.g. to add a new cell without clicking \"\"+ code\"), go to \"Tools --> Keyboard shortcuts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsOC0voR33_F"
   },
   "source": [
    "### Problem 1 [2p]\n",
    "\n",
    "First, get familiar with Python at https://docs.python.org/2/tutorial/. Then, get\n",
    "to know the capabilities of NumPy, the prime numerical library of Python http://www.numpy.org/, for instance with the tutorial at http://wiki.scipy.org/Tentative_NumPy_Tutorial.\n",
    "\n",
    "You might also need:\n",
    "  1. another intro to NumPy,\n",
    "http://people.duke.edu/~ccc14/pcfb/numerics.html\n",
    "  2. a better interactive shell for Python,\n",
    "http://ipython.org/\n",
    "  3. access to IPython through an ordinary web browser,\n",
    "http://ipython.org/notebook.html\n",
    "  4. a plotting library for Python.\n",
    "http://matplotlib.org/\n",
    "\n",
    "**a) Declare variables:**\n",
    "1. $a=10$,\n",
    "2. $b=2.5\\times 10^{23}$,\n",
    "3. $c=2+3i$, where $i$ is an imaginary unit,\n",
    "4. $d=e^{i2\\pi/3}$, where $i$ is an imaginary unit, $e$ is the Euler's number (use `exp`, `pi`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8sd7jJhd33_G"
   },
   "outputs": [],
   "source": [
    "# TODO: Complete the declarations\n",
    "a = 10\n",
    "b = 2.5 * 10**23\n",
    "c = np.complex(2, 3)\n",
    "d = np.exp(np.complex(0, 2 * pi / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bP0hAHvN33_K"
   },
   "source": [
    "**b) Declare vectors:**\n",
    "1. $aVec=\\begin{bmatrix} 3.14 & 15 & 9 & 26 \\end{bmatrix}$,\n",
    "2. $bVec=\\begin{bmatrix} 2.71 & 8 & 28 & 182 \\end{bmatrix}^\\intercal$ (column vector),\n",
    "3. $cVec=\\begin{bmatrix} 5 & 4.8 & \\cdots & -4.8 & -5 \\end{bmatrix}$ (vector of numbers from $5$ to $-5$ decreasing by $0.2$),\n",
    "4. $dVec=\\begin{bmatrix} 10^0 & 10^{0.01} & \\cdots & 10^{0.99} & 10^1 \\end{bmatrix}$ (logarithmically spaced numbers from 1 to 10, use `logspace` and make sure, that the result has correct length!),\n",
    "5. $eVec=Hello$ ($eVec$ is a string of characters, thus a vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37RmkuW533_L"
   },
   "outputs": [],
   "source": [
    "aVec = np.array([3.14, 15, 9, 26]) \n",
    "bVec = np.transpose([[2.71, 8, 28, 182]])\n",
    "cVec = np.linspace(start=5, stop=-5, num=51)\n",
    "dVec = np.logspace(start=1, stop=10, num=101)\n",
    "eVec = np.chararray((1, 5))\n",
    "eVec = 'Hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C58YJtEU33_O"
   },
   "source": [
    "**c) Declare matrices:**\n",
    "1. $aMat=\\begin{bmatrix}\n",
    "                    2      & \\cdots & 2 \\\\\n",
    "                    \\vdots & \\ddots & \\vdots \\\\\n",
    "                    2      & \\cdots & 2\n",
    "                \\end{bmatrix}$,\n",
    "<br/>\n",
    "matrix $9\\times 9$ filled with 2s (use `ones` or `zeros`),\n",
    "2. $bMat=\\begin{bmatrix}\n",
    "                    1      & 0      & \\cdots &        & 0      \\\\\n",
    "                    0      & \\ddots & 0      &        & 0      \\\\\n",
    "                    \\vdots & 0      & 5      & 0      & \\vdots \\\\\n",
    "                           &        & 0      & \\ddots & 0      \\\\\n",
    "                    0      &        & \\cdots & 0      & 1\n",
    "                \\end{bmatrix}$,\n",
    "<br/>\n",
    "matrix $9\\times 9$ filled with zeros, with $\\begin{bmatrix} 1 & 2 & 3 & 4 & 5 & 4 & 3 & 2 & 1 \\end{bmatrix}$ on its diagonal (use `zeros`, `diag`),\n",
    "3. $cMat=\\begin{bmatrix}\n",
    "                    1      & 11     & \\cdots & 91     \\\\\n",
    "                    2      & 12     & \\ddots & 92     \\\\\n",
    "                    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                    10     & 20     & \\cdots & 100\n",
    "                \\end{bmatrix}$,\n",
    "<br/>\n",
    "matrix $10\\times 10$, columns of which form the vector $1:100$ (use `reshape`),\n",
    "4. $dMat=\\begin{bmatrix}\n",
    "                    NaN & NaN & NaN & NaN \\\\\n",
    "                    NaN & NaN & NaN & NaN \\\\\n",
    "                    NaN & NaN & NaN & NaN\n",
    "                \\end{bmatrix}$,\n",
    "<br/>\n",
    "matrix $3\\times 4$ filled with `NaN`s (use... `NaN`),\n",
    "5. $eMat=\\begin{bmatrix}\n",
    "                    13  & -1  & 5  \\\\\n",
    "                    -22 & 10  & -87\n",
    "                \\end{bmatrix}$,\n",
    "<br/>\n",
    "6. $fMat$ filled with random natural numbers from $[-3,3]$ (use `rand` and `floor` or `ceil`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bdd1oUeI33_P"
   },
   "outputs": [],
   "source": [
    "aMat = np.full((9, 9), 2)\n",
    "bMat = np.diag(np.concatenate((np.arange(start=1, stop=5),\n",
    "                               np.arange(start=5, stop=0, step=-1))))\n",
    "cMat = np.transpose(np.arange(start=1, stop=101).reshape(10, 10))\n",
    "dMat = np.full((3, 4), np.nan)\n",
    "eMat = np.array([[13, -1, 5], [-22, 10, -87]])\n",
    "fMat = np.ceil(np.random.rand(10, 10) * 7 - 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqtKQi1Q33_T"
   },
   "source": [
    "** d) Declare a multiplication table ** as a $10\\times 10$ matrix `mulMat`. Use matrix/vector multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWqHq-vK33_U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
       "       [  2,   4,   6,   8,  10,  12,  14,  16,  18,  20],\n",
       "       [  3,   6,   9,  12,  15,  18,  21,  24,  27,  30],\n",
       "       [  4,   8,  12,  16,  20,  24,  28,  32,  36,  40],\n",
       "       [  5,  10,  15,  20,  25,  30,  35,  40,  45,  50],\n",
       "       [  6,  12,  18,  24,  30,  36,  42,  48,  54,  60],\n",
       "       [  7,  14,  21,  28,  35,  42,  49,  56,  63,  70],\n",
       "       [  8,  16,  24,  32,  40,  48,  56,  64,  72,  80],\n",
       "       [  9,  18,  27,  36,  45,  54,  63,  72,  81,  90],\n",
       "       [ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mulMat = np.transpose([np.arange(start=1, stop=11)]) @ [np.arange(start=1, stop=11)]\n",
    "mulMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xIm6lT133_Y"
   },
   "source": [
    "** e) Compute elemwise using values from b).**\n",
    "For instance, the first element of $xVec[0]$ should be equal to\n",
    "\n",
    "\\begin{equation}\n",
    "1/(\\sqrt{2\\pi2.5^2}) e^{-cVec[0]^2 / (2\\cdot\\pi 2.5^2)}.\n",
    "\\end{equation}\n",
    "\n",
    "1. $xVec=1/(\\sqrt{2\\pi2.5^2}) e^{-cVec^2 / (2\\cdot\\pi 2.5^2)}$\n",
    "2. $yVec=\\sqrt{(aVec^\\intercal)^2 + bVec^2}$\n",
    "3. $zVec=\\log_{10}(1/dVec)$, using `log10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtH-kSU733_Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0844286 , 0.08874945, 0.09310157, 0.09746835, 0.10183228,\n",
       "       0.10617507, 0.11047778, 0.11472091, 0.11888457, 0.12294862,\n",
       "       0.12689283, 0.13069705, 0.13434136, 0.13780626, 0.14107285,\n",
       "       0.14412296, 0.14693938, 0.14950594, 0.15180777, 0.15383133,\n",
       "       0.15556462, 0.15699729, 0.1581207 , 0.15892806, 0.15941445,\n",
       "       0.15957691, 0.15941445, 0.15892806, 0.1581207 , 0.15699729,\n",
       "       0.15556462, 0.15383133, 0.15180777, 0.14950594, 0.14693938,\n",
       "       0.14412296, 0.14107285, 0.13780626, 0.13434136, 0.13069705,\n",
       "       0.12689283, 0.12294862, 0.11888457, 0.11472091, 0.11047778,\n",
       "       0.10617507, 0.10183228, 0.09746835, 0.09310157, 0.08874945,\n",
       "       0.0844286 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xVec = 1 / np.sqrt(2 * pi * 6.25) * np.exp(-cVec**2 / (2 * pi * 6.25))\n",
    "yVec = np.sqrt(np.transpose(aVec**2) + bVec**2)\n",
    "zVec = np.log10(1/dVec)\n",
    "xVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBhf74F_33_d"
   },
   "source": [
    "** f) Compute with matrix/vector operations using values from c).**\n",
    "\n",
    "**NOTE:** Every multiplication (and power) in this subtask is a [matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication).\n",
    "1. $xMat=(aVec\\cdot bVec)aMat^2$,\n",
    "2. $yMat=bVec\\cdot aVec$\n",
    "<br/>\n",
    "(remember, that matrix multiplication is not commutative),\n",
    "4. $zMat=\\lvert cMat\\rvert (aMat\\cdot bMat)^\\intercal$, where $\\lvert A\\rvert$ denotes determinant of $A$ (use `det`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjdLR34u33_e"
   },
   "outputs": [],
   "source": [
    "xMat = aVec @ bVec * (aMat @ aMat)\n",
    "yMat = bVec @ [aVec]\n",
    "zMat = np.linalg.det(cMat) * np.transpose(aMat @ bMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJ3xTXgV33_i"
   },
   "source": [
    "** g) Declare `ismagic(A)` function ** which checks if matrix $A$ is a [magic square](https://en.wikipedia.org/wiki/Magic_square) and returns a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCNJUx_G33_j"
   },
   "outputs": [],
   "source": [
    "def ismagic(A):\n",
    "    \n",
    "    # Check if A could be a magic square\n",
    "    if A.shape[0] != A.shape[1] or len(A.shape) != 2:\n",
    "        return false\n",
    "    \n",
    "    # Calculate all sums of elements in columns,\n",
    "    # rows and diagonals\n",
    "    sums = np.hstack((np.sum(A, axis=0),\n",
    "                      np.sum(A, axis=1),\n",
    "                      np.sum(np.diag(A)),\n",
    "                      np.sum(np.diag(np.rot90(A)))))\n",
    "    \n",
    "    # Check if all are the same\n",
    "    return np.all(np.equal(sums, sums[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Es80_WJM33_n"
   },
   "source": [
    "### k-Nearest Neighbors\n",
    "\n",
    "The following excerpt of code loads the data describing iris flowers\n",
    "and shows relations between their length and petal width for three\n",
    "species (namely: setosa, versicolor, virginica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "hOvm2SEE33_q",
    "outputId": "3b5eeae1-f4d9-44b1-bb70-a78723214b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Targets:  ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sklearn is a large collection of machine learning algorithms\n",
    "# here we’ll use it only for the built-in iris dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print('Features: ', iris.feature_names)\n",
    "print('Targets: ', iris.target_names)\n",
    "\n",
    "petal_length = iris.data[:, iris.feature_names.index('petal length (cm)')]\n",
    "petal_width = iris.data[:, iris.feature_names.index('petal width (cm)')]\n",
    "\n",
    "for target in set(iris.target):\n",
    "    example_ids = target == iris.target\n",
    "    plt.scatter(petal_length[example_ids], petal_width[example_ids],\n",
    "                label=iris.target_names[target], color='bgr'[target],\n",
    "                marker='x', alpha=0.7)\n",
    "unknown = np.array([\n",
    "    [1.5, 0.3],\n",
    "    [4.5, 1.2],\n",
    "    [5.5, 2.3],\n",
    "    [5.1, 1.7]\n",
    "])\n",
    "plt.scatter(unknown[:, 0], unknown[:, 1], marker='v',\n",
    "            color='gray', s=50, label='??')\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('petal width (cm)')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2khewKZ33_w"
   },
   "source": [
    "Based on these two features, it is easy to distinguish iris setosa from the two remaining species. Yet iris versicolor and virginica remain mixed together. \n",
    "\n",
    "Looking closely at the plot, we might estimate the species of the selected unknown irises (gray triangles). For three of them the answer seems obvious – they belong in uniformly-colored areas covered by one species only. Yet unknown iris flower in (5.1, 1.7) is troublesome – it lays on the boundary of versicolor and virginica clusters. We can assume, that its species is the one of the closest one to it, coming from the training set (and so having a label). \n",
    "\n",
    "K-Nearest Neighbors method (http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) solves the classification problem, i.e. sets class labels (species in case of irises) of a previously unseen sample by choosing the most common class among the top k neighbors of the sample in question (for instance according to the Euclidean distance). Thus, the k-Nearest Neighbors algorithm works as follows. For each unlabeled sample x:\n",
    "1. Find k nearest neighbors among the labeled samples.\n",
    "2. Set the most common label among them as label of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-G-sMUw33_x"
   },
   "source": [
    "#### Problem 2 [2p]\n",
    "\n",
    "1.  **[1p]** Load the iris data (in Python it’s built-in into machine learning libraries, use sklearn.datasets.load_iris), the data is also available on-line at https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "2.  **[1p]** Irises are described with 4 attributes: petal and sepal widths and lengths. We often plot such data as matrices depicting relationships between pairs of attributes (the diagonal of which holds an ordinary histogram). Write code making a plot like the one below. Please pay attention to the details: make a proper legend and correctly label the axes.\n",
    "\n",
    "<img src=\"https://github.com/janchorowski/nn_assignments/blob/nn18/assignment1/iris4x4.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot two chosen features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_two_features(features: tuple,\n",
    "                      plot: plt=plt,\n",
    "                      data: np.array=iris.data,\n",
    "                      marker_size: int=15) -> plt:\n",
    "    \n",
    "    n_labels = np.unique(iris.target).size\n",
    "    \n",
    "    for label in range(n_labels):\n",
    "        \n",
    "        # Array of examples satysfying equality with actual label\n",
    "        to_plot = iris.target == label\n",
    "        \n",
    "        # Disable grid\n",
    "        plot.grid(False)\n",
    "\n",
    "        # Plot exemples satysfying equality with actual label\n",
    "        plot.scatter(data[to_plot, features[0]], data[to_plot, features[1]], s=marker_size)\n",
    "\n",
    "plot_two_features((0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Plot distribution of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hist_feature(feature: int,\n",
    "                      plot: plt=plt,\n",
    "                      data: np.array=iris.data,\n",
    "                      n_bins=10) -> plt:\n",
    "    \n",
    "    # Disable grid\n",
    "    plot.grid(False)\n",
    "    \n",
    "    # Plot \n",
    "    plot.hist(data[:, feature], bins=n_bins)\n",
    "    \n",
    "hist_feature(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All possible subplots of iris features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6sG0bxf33_y"
   },
   "source": [
    "#### Problem 3 [2p]\n",
    "\n",
    "Implement the k-Nearest Neighbors algorithm. Try to\n",
    "take advantage of matrix calculus rather than using for loops.\n",
    "\n",
    "**Tip:** What is computed by \\begin{equation} \\sqrt{(X - Y)^T (X - Y)} \\end{equation} when both X and Y are vectors?\n",
    "\n",
    "**Tip:** Try to use broadcasting (NumPy: http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) and built-ins sort, numpy.sort, numpy.argsort (sorting), scipy.stats.mode (choosing the most common element of the set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iZtHs5A33_z"
   },
   "source": [
    "#### Problem 4 [2p]\n",
    "Consider the following experiment:\n",
    "1. We scramble the data and split it into two parts - training set (66.6% of all samples) and test set (33.4%).\n",
    "2. Based on the training set, we use the k-NN algorithm to predict the labels on the test set.\n",
    "3. We then check the number of errors and write it down.\n",
    "\n",
    "Do this 500 times for k ∈ {1, 3, 5, ..., 19}. Plot a function of the average number of errors\n",
    "as the function of k. It should be similar to the one below.\n",
    "\n",
    "<img src=\"https://github.com/janchorowski/nn_assignments/blob/nn18/assignment1/knn.png?raw=1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A86GnZpa33_0"
   },
   "source": [
    "#### Problem 5 [2p] \n",
    "\n",
    "Apply the K-Nearest Neighbors (K-NN) algorithm to the MNIST and CIFAR10 datasets. \n",
    "\n",
    "The MNIST (http://yann.lecun.com/exdb/mnist/) dataset consists of normalized (centered and stretched) scans of hand-written digits. Specifically, each element of the dataset is a 28 × 28 grayscale image, thus having 764 8-bit pixels. \n",
    "\n",
    "The CIFAR10 (http://www.cs.toronto.edu/~kriz/cifar.html) dataset consists of small, 32 by 32 pixels, RGB images belonging to 10 categories.\n",
    "\n",
    "1. **[1p]** Download and load the MNIST and CIFAR10 datasets. For both datasets, display a few objects from each of the classes, paying attention to aesthetics and clarity of your presentation. **Note:** You already downloaded the datasets in \"Setup\" section. Please use the code below to get started.\n",
    "\n",
    "2. **[2p]** Apply a k-NN classifier to the MNIST and CIFAR10 datasets. First, divide the training set into two parts, which we will call training and validation. On MNIST use the first 50000 samples for training and the last 10000 for validation. On CIFAR10, use 40000 to train and 10000 for validation. Then find the optimal number of neighbors by assessing the accuracy on the validation set. You do not need to repeat this experiment multiple times. Finally, compute the accuracy on the test set obtained with the best previously chosen number of neighbors. On MNIST you should get about 3% errors, while on CIFAR10 you should get about 70% errors. Why CIFAR10 is harder than MNIST? Pick a few mislabeled samples from the test dataset and plot them along with the correct ones. **Note:**\n",
    "  * MNIST and CIFAR10 are much larger than the Iris dataset. A good implementation may need a few minutes depending on your runtime type. Please optimize your algorithm:\n",
    "  * Compute the distances only once, then test for different values of k.\n",
    "  * Use vectorized expressions to compute the distance. It is possible to compute all distances between the training and testing points in one expression. Hint: think about the vectorized expression \\begin{equation}(X - Y)^T (X - Y)\\end{equation}.\n",
    "  * You can use single precision numbers in computation.\n",
    "  * If your code is taking a long time to execute, please save its results before the lab session.\n",
    "\n",
    "**Note:** in NumPy, matrices have its own data type (dtype), which is retained during\n",
    "calculations. Please pay attention to it. I particular, do not subtract values of data types not\n",
    "having the sign bit, do not divide integers, etc. Results of such operations will not be\n",
    "automatically casted to types having the required precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AvAeiDN33_1"
   },
   "outputs": [],
   "source": [
    "with np.load('mnist.npz') as data:\n",
    "    mnist_full_train_data_uint8 = data['train_data']\n",
    "    mnist_full_train_labels_int64 = data['train_labels']\n",
    "    mnist_test_data_uint8 = data['test_data']\n",
    "    mnist_test_labels_int64 = data['test_labels']\n",
    "        \n",
    "# Split train data into train and validation sets\n",
    "mnist_train_data_uint8 = mnist_full_train_data_uint8[:50000]\n",
    "mnist_train_labels_int64 = mnist_full_train_labels_int64[:50000]\n",
    "mnist_valid_data_uint8 = mnist_full_train_data_uint8[50000:]\n",
    "mnist_valid_labels_int64 = mnist_full_train_labels_int64[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "aenFc3L633_4",
    "outputId": "8da070dc-d6d9-4431-ae08-0aaa66a0a836"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-56a2233d70b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_train_data_uint8\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mhttps://raw.githubusercontent.com/janchorowski/nn_assignments/nn18//common/plotting.py\u001b[0m in \u001b[0;36mplot_mat\u001b[0;34m(mat, scaleIndividual, colorbar, prop, gutters, scale_fun, **kwargs)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "plot_mat(mnist_train_data_uint8[:20, None], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wwii9AQN33_8"
   },
   "outputs": [],
   "source": [
    "with np.load('cifar.npz') as data:\n",
    "    cifar_full_train_data_uint8 = data['train_data']\n",
    "    cifar_full_train_labels_int64 = data['train_labels']\n",
    "    cifar_test_data_uint8 = data['test_data']\n",
    "    cifar_test_labels_int64 = data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jut2P5Rj34AD"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: plot an example of each class on MNIST and on CIFAR-10\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cREkeVz34AH"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "def KNN(train_X, train_Y, test_X, test_Y, ks, batch_size=200):\n",
    "    \"\"\"\n",
    "    Compute error rate for various \n",
    "    \"\"\"\n",
    "    errs = np.zeros((len(ks),))\n",
    "    for i in xrange(0, test_Y.shape[0], batch_size):\n",
    "        batch_X = test_X[i:i + batch_size]\n",
    "        batch_Y = test_Y[i:i + batch_size]\n",
    "        print(\"Examples %d:%d Computing distances... \" %\n",
    "              (i, i + batch_size), end='')\n",
    "\n",
    "        #\n",
    "        # TODO: fill in an efficient distance matrix computation\n",
    "        #\n",
    "        dists = TODO\n",
    "\n",
    "        print(\"Sorting... \", end='')\n",
    "        closest = np.argsort(dists, 0)\n",
    "\n",
    "        print(\"Computing errors...\")\n",
    "        targets = train_Y[closest]\n",
    "\n",
    "        for ki, k in enumerate(ks):\n",
    "            predictions, unused_counts = mode(targets[:k, :], axis=0)\n",
    "            predictions = predictions.ravel()\n",
    "            #\n",
    "            # TODO: fill in error count computation\n",
    "            #\n",
    "            errs[ki] += TODO\n",
    "\n",
    "    errs /= test_Y.shape\n",
    "    return np.vstack((ks, errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTuX5ql334AO"
   },
   "outputs": [],
   "source": [
    "# Now find the best k on the validation set\n",
    "\n",
    "mnist_validation_errs = KNN(\n",
    "    mnist_train_data_uint8, mnist_train_labels_int64,\n",
    "    mnist_valid_data_uint8, mnist_valid_labels_int64,\n",
    "    [1, 3, 5, 7, 9])\n",
    "\n",
    "plot(mnist_validation_errs[0, :], mnist_validation_errs[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5j4eGVN34AR"
   },
   "outputs": [],
   "source": [
    "# Now use the best k to compute the test error\n",
    "\n",
    "best_K = TODO\n",
    "\n",
    "mnist_full_train_data_uint8 = mnist_train_dataset.train_data.numpy()\n",
    "mnist_full_train_labels_int64 = mnist_train_dataset.train_labels.numpy()\n",
    "\n",
    "mnist_test_errs = KNN(mnist_full_train_data_uint8, \n",
    "                      mnist_full_train_labels_int64,\n",
    "                      mnist_test_data_uint8, \n",
    "                      mnist_test_labels_int64, [best_K])\n",
    "print(\"When k=%d the test error rate is %.1f%%\" %\n",
    "      (mnist_test_errs[0, 0], mnist_test_errs[1, 0] * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g88neUhM34AU"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Now repeat the k-NN training for CIFAR10\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1qq8XLOt34AX"
   },
   "source": [
    "### Locality sensitive hashing\n",
    "\n",
    "Problem 5 was about speeding up the inference using loops implicitly present in matrix multiplication instead of explicit loops in Python. In this problem, we will explore a strategy to truly reduce the total number of computations required to find nearest neighbors without sacrificing too much accuracy.\n",
    "\n",
    "To speed up nearest neighbor search we will employ *Locality Sensitive Hashing (LSH)* functions. For a given distance metric, the locality sensitive hash should put items that are similar into the same bucket. Notice that this is essentially a design choice opposite to traditional cryptographic hash functions that should amplify the difference of similar inputs (typically we want that small perturbations of data result in large changes to the hash value).\n",
    "\n",
    "One of the simplest implementations of LSH approximates the cosine distance. Let $x\\in \\mathbb{R}^N$ and $y\\in \\mathbb{R}^N$ be two vectors. Their cosine distance is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "    d_\\text{cos}(x,y) = \\frac{x \\cdot y}{\\|x\\| \\|y\\|} = \\cos\\left(\\theta(x,y)\\right),\n",
    "\\end{equation}\n",
    "where $\\theta(x,y)$ is the unsigned angle between $x$ and $y$.\n",
    "\n",
    "We will construct a family $H$ of hash functions that are an LSH for angle distances (an approximation to cosine distance). Assume $p\\in \\mathbb{R}^N$ is a random vector (components are sampled from the normal distribution) of length 1. Then define the hash function $h(x) = \\text{sgn}(x\\cdot p)$, where $\\text{sgn()}$ is the sign function. It can be proven that:\n",
    "\n",
    "\\begin{equation}\n",
    "    p_{h\\in H}[h(x)=h(y)] = 1 - \\frac{\\theta(x,y)}{\\pi}.\n",
    "\\end{equation}\n",
    "\n",
    "The equation means that the probability of a hash collision grows as the the angle between two vectors gets smaller. Therefore, vectors that are close according to the cosine distance will be put with high probability into the same bin (we use the fact that for small $\\theta$ we can approximate $\\cos(\\theta) = 1 - \\theta/\\pi$.\n",
    "\n",
    "We will say that a family of randomly chosen hash functions $H$ is $(d_1, d_2, p_1, p_2)$-sensitive with respect to a distance metric $d$ if for any $x$ and $y$:\n",
    "1. If $d(x,y) \\leq d_1$ then $p_{h\\in H}[h(x)=h(y)] \\geq p_1$.\n",
    "2. If $d(x,y) \\geq d_2$ then $p_{h\\in H}[h(x)=h(y)] \\leq p_2$.\n",
    "\n",
    "For example, our family of randomly chosen hyperplanes is $(d_1, d_2, (1-d_1)/\\pi, (1-d_2)/\\pi)$-sensitive.\n",
    "\n",
    "Ideally, vectors should be placed into the same bin with a high probability if their distance is smaller than a threshold, and with a low probability if their distance is larger that the threshold. By combining hashing functions we can get closer to this ideal sensitivity.\n",
    "\n",
    "Given a family of hash functions $H$ with sensitivity $(d_1, d_3, p_1, p_2)$ we can construct a new family $H'$ by combining $r$ functions from $H$:\n",
    "1. AND: let $h=[h_1, h_2, \\ldots, h_r] \\in H'$ and $h(x)=h(y)$ if and only if $\\forall_i h_i(x)=h_i(y)$. Then $H'$ is $(d_1, d_2, (p_1)^r, (p_2)^r)$-sensitive.\n",
    "2. OR: let $h=[h_1, h_2, \\ldots, h_r] \\in H'$ and $h(x)=h(y)$ if and only if $\\exists_i h_i(x)=h_i(y)$. Then $H'$ is $(d_1, d_2, 1-(1-p_1)^r, 1-(1-p_2)^r)$-sensitive.\n",
    "\n",
    "AND makes all probabilities shrink, but properly choosing $r$ we can make the lower probability approach 0 while the higher does not. Conversely, OR makes all probabilities grow, we can make the upper probability approach 1 while the lower does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OutHmcfp8zLo"
   },
   "source": [
    "#### Problem 6 [2-4p bonus] \n",
    "\n",
    "1. **[1bp]** **Note:** you can show sketches of proofs for this assignment.\n",
    "    1. Show that angle between vectors is a metric (https://en.wikipedia.org/wiki/Metric_(mathematics)).\n",
    "    \n",
    "    2. Show that $p_{h\\in H}[h(x)=h(y)] = 1 - \\frac{\\theta(x,y)}{\\pi}$ for $h$ computed using a randomly chosen hyperplane.\n",
    "\n",
    "    3. Show the properties of either AND or OR boosting of LSH.\n",
    "\n",
    "3. **[1-3bp]** Reimplement k-Nearest Neighbors for MNIST classification using the cosine distance instead of the Euclidean distance. Choose a sensible value of $k$. Use Locality Sensitive Hashing to achieve an error rate no greater than $150\\%$ of the original error rate with at least a $90\\%$ speedup (i.e., by considering on average at most 5000 training samples per query image). For a few settings plot the speedup-vs-accuracy relation.\n",
    "\n",
    "  **Note:** points will be awarded based on ingenuity of your solution. Feel free to explore your own ideas!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
